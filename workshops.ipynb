{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read OpenAI API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(\"secrets.env\")\n",
    "OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Call to OpenAI API\n",
    "\n",
    "**Pros of Using OpenAI Chat API in a Company's Chatbot:**\n",
    "\n",
    "1. **Advanced Natural Language Processing (NLP):** The API uses state-of-the-art NLP, allowing the chatbot to understand and respond to user queries more effectively, even with complex or ambiguous language.\n",
    "2. **Versatility:** OpenAI's API can handle a wide variety of topics, making the chatbot adaptable to diverse user needs across multiple domains without extensive retraining.\n",
    "3. **Scalability:** The API can handle high volumes of requests, enabling businesses to scale their chatbot solutions without worrying about performance degradation.\n",
    "4. **Continuous Improvement:** OpenAI continually updates and improves its models, so your chatbot can benefit from cutting-edge advancements in AI without needing significant internal resources.\n",
    "5. **Rapid Deployment:** Implementing the OpenAI Chat API can accelerate the development and deployment of a chatbot, reducing time-to-market compared to building a custom NLP system from scratch.\n",
    "\n",
    "**Cons of Using OpenAI Chat API in a Company's Chatbot:**\n",
    "\n",
    "1. **Cost:** Usage of the API incurs ongoing costs based on the volume of requests, which can add up, especially for high-traffic applications.\n",
    "2. **Limited Customization:** Although versatile, the API may not always meet highly specific business requirements, requiring additional layers of customization that can be complex to implement.\n",
    "3. **Data Privacy Concerns:** Using a third-party API may raise concerns about data privacy and security, particularly in industries that handle sensitive customer information.\n",
    "4. **Dependency on External Service:** Relying on an external service like OpenAI means potential downtime, rate-limiting, or API changes that are beyond the company's control.\n",
    "5. **Ethical Considerations:** AI-generated responses can sometimes produce unexpected or inappropriate content, which may require careful monitoring and mitigation strategies to maintain brand integrity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI, or artificial intelligence, refers to the capability of a machine or computer system to perform tasks that would typically require human intelligence. This includes tasks such as learning, reasoning, problem-solving, understanding and interpreting natural language, and recognizing patterns in data. AI systems can learn from data, adapt to new inputs, and perform tasks with a level of autonomy. Some common applications of AI include virtual assistants, image recognition, natural language processing, and autonomous vehicles.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"What is AI?\",\n",
    "        }\n",
    "    ],\n",
    "    model=\"gpt-3.5-turbo\",\n",
    ")\n",
    "\n",
    "print(chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do I need to write utility classes on my own? - Utilise LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI stands for artificial intelligence, which refers to the simulation of human intelligence processes by machines, especially computer systems. AI involves the development of algorithms and software that enable computers to perform tasks that typically require human intelligence, such as visual perception, speech recognition, decision-making, and language translation. AI technologies include machine learning, natural language processing, computer vision, and robotics.\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-3.5-turbo\", api_key=OPENAI_API_KEY)\n",
    "response = model.invoke([HumanMessage(content=\"What is AI?\")])\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Of course! I can provide more information or elaborate on the topic you're interested in. Just let me know what specifically you would like to know more about.\n"
     ]
    }
   ],
   "source": [
    "response = model.invoke([HumanMessage(content=\"It is really interesting what you have written. Can you say more about it?\")])\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see - the model by itself doesn't remember the history of messages. We need to pass all messages to get the desired answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Of course! Artificial intelligence can be categorized into two main types: narrow AI and general AI. Narrow AI, also known as weak AI, is designed to perform specific tasks and is limited to a narrow scope of functions. Examples of narrow AI include virtual assistants like Siri and Alexa, recommendation algorithms on streaming services, and facial recognition technology.\n",
      "\n",
      "On the other hand, general AI, also known as strong AI, refers to a system that possesses the ability to understand, learn, and apply knowledge across a wide range of tasks similar to human intelligence. General AI is still a theoretical concept and is not yet fully realized in practice.\n",
      "\n",
      "AI technologies such as machine learning, deep learning, natural language processing, and computer vision play a crucial role in the development of artificial intelligence systems. These technologies enable computers to analyze large amounts of data, recognize patterns, and make decisions without human intervention.\n",
      "\n",
      "AI has applications across various industries, including healthcare, finance, transportation, marketing, and entertainment. It has the potential to revolutionize how businesses operate, improve healthcare outcomes, enhance customer experiences, and optimize processes.\n",
      "\n",
      "However, AI also raises ethical and societal concerns, such as job displacement, data privacy, bias in algorithms, and the potential for misuse. As AI technology continues to advance, it is essential to consider these implications and ensure that AI systems are developed and deployed responsibly.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "\n",
    "response = model.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"What is AI?\"),\n",
    "        AIMessage(\n",
    "            content=\"AI, or artificial intelligence, refers to the development of computer systems that can perform tasks that typically require human intelligence, such as visual perception, speech recognition, decision-making, and language translation. AI technology aims to mimic human cognitive functions and improve efficiency and accuracy in tasks that were previously only achievable by humans.\"\n",
    "        ),\n",
    "        HumanMessage(content=\"It is really interesting what you have written. Can you say more about it?\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Message History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.chat_history import (\n",
    "    BaseChatMessageHistory,\n",
    "    InMemoryChatMessageHistory,\n",
    ")\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "store = {}\n",
    "\n",
    "\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = InMemoryChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "\n",
    "chain_with_history = RunnableWithMessageHistory(model, get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI stands for artificial intelligence, which refers to the simulation of human intelligence processes by machines, especially computer systems. This includes learning, reasoning, problem-solving, perception, language understanding, and decision-making. AI technologies are used in various applications such as speech recognition, image processing, natural language processing, robotics, and autonomous vehicles.\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"session_id\": \"session_1\"}}\n",
    "\n",
    "response = chain_with_history.invoke(\n",
    "    [HumanMessage(content=\"What is AI?\")],\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! Artificial intelligence is a rapidly evolving field that aims to create intelligent machines that can perform tasks that typically require human intelligence. AI systems are designed to learn from data, adapt to new information, and make decisions based on patterns and trends in the data. There are different types of AI, including narrow AI (or weak AI) which is designed for specific tasks, and general AI (or strong AI) which aims to replicate human-level intelligence across a wide range of tasks.\n",
      "\n",
      "Some common techniques used in AI include machine learning, deep learning, neural networks, natural language processing, computer vision, and reinforcement learning. These techniques enable AI systems to analyze and interpret data, recognize patterns, and make predictions or decisions based on the information available to them.\n",
      "\n",
      "AI is being used in a wide range of industries and applications, including healthcare, finance, transportation, marketing, customer service, and many others. It has the potential to revolutionize how we work, live, and interact with technology in the future. However, there are also ethical and societal implications to consider, such as job displacement, privacy concerns, bias in AI algorithms, and the potential for misuse of AI technology.\n"
     ]
    }
   ],
   "source": [
    "response = chain_with_history.invoke(\n",
    "    [HumanMessage(content=\"It is really interesting what you have written. Can you say more about it?\")],\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After a session_id change, another user will not have access to the previous conversation history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm sorry, I cannot remember what you were asking about earlier as I do not have the capability to retain information from previous interactions. Could you please provide more context or details so I can assist you further?\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"session_id\": \"session_2\"}}\n",
    "\n",
    "response = chain_with_history.invoke(\n",
    "    [HumanMessage(content=\"What was I asking about earlier?\")],\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different types of memories\n",
    "\n",
    "- all messages (presented earlier)\n",
    "- trim messages\n",
    "- summarize conversation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trim messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: Nice to meet you, Bob! How can I assist you today?\n",
      "2: Your name is Bob.\n",
      "3: I'm sorry, I do not know your name as I am an AI assistant and do not have that information.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "\n",
    "# Trim to four messages\n",
    "def trim_messages(chain_input):\n",
    "    current_store = store[config[\"configurable\"][\"session_id\"]]\n",
    "    if len(current_store.messages) <= 4:\n",
    "        return False\n",
    "\n",
    "    current_store.clear()\n",
    "\n",
    "    for message in current_store.messages[-4:]:\n",
    "        current_store.add_message(message)\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "chain_with_trimming = RunnablePassthrough.assign(messages_trimmed=trim_messages) | chain_with_history\n",
    "\n",
    "response = chain_with_trimming.invoke(\n",
    "    {\"input\": \"My name is Bob.\"},\n",
    "    config=config,\n",
    ")\n",
    "print(f\"1: {response.content}\")\n",
    "\n",
    "response = chain_with_trimming.invoke(\n",
    "    {\"input\": \"What is my name?\"},\n",
    "    config=config,\n",
    ")\n",
    "print(f\"2: {response.content}\")\n",
    "\n",
    "response = chain_with_trimming.invoke(\n",
    "    {\"input\": \"What is my name?\"},\n",
    "    config=config,\n",
    ")\n",
    "print(f\"3: {response.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarize conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: Nice to meet you, Bob! How can I assist you today?\n",
      "2: You introduced yourself by typing your name, Bob, in your message.\n",
      "3: You introduced yourself by typing your name, \"Bob.\"\n",
      "[AIMessage(content='In the chat conversation, Bob introduced himself by typing his name, and the AI assistant acknowledged his name. The AI assistant expressed readiness to assist Bob with any queries or tasks he may have.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 38, 'prompt_tokens': 94, 'total_tokens': 132}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-ba73d24e-ff3c-4e30-8c45-1b47bc0c9094-0', usage_metadata={'input_tokens': 94, 'output_tokens': 38, 'total_tokens': 132}), HumanMessage(content='How did I introduce myself?'), AIMessage(content='You introduced yourself by typing your name, \"Bob.\"', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 11, 'prompt_tokens': 55, 'total_tokens': 66}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-004244ab-d51a-4866-a1c8-404be43880c5-0', usage_metadata={'input_tokens': 55, 'output_tokens': 11, 'total_tokens': 66})]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "\n",
    "def summarize_messages(chain_input):\n",
    "    current_store = store[config[\"configurable\"][\"session_id\"]]\n",
    "    if len(current_store.messages) == 0:\n",
    "        return False\n",
    "\n",
    "    summarization_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "            (\n",
    "                \"user\",\n",
    "                \"Distill the above chat messages into a single summary message. Include as many specific details as you can.\",\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    summarization_chain = summarization_prompt | model\n",
    "    summary_message = summarization_chain.invoke({\"chat_history\": current_store.messages})\n",
    "\n",
    "    current_store.clear()\n",
    "    current_store.add_message(summary_message)\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "chain_with_summarization = RunnablePassthrough.assign(messages_summarized=summarize_messages) | chain_with_history\n",
    "\n",
    "response = chain_with_summarization.invoke(\n",
    "    {\"input\": \"My name is Bob.\"},\n",
    "    config=config,\n",
    ")\n",
    "print(f\"1: {response.content}\")\n",
    "\n",
    "response = chain_with_summarization.invoke(\n",
    "    {\"input\": \"How did I introduce myself?\"},\n",
    "    config=config,\n",
    ")\n",
    "print(f\"2: {response.content}\")\n",
    "\n",
    "response = chain_with_summarization.invoke(\n",
    "    {\"input\": \"How did I introduce myself?\"},\n",
    "    config=config,\n",
    ")\n",
    "print(f\"3: {response.content}\")\n",
    "print(store[config[\"configurable\"][\"session_id\"]].messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompting techniques\n",
    "\n",
    "- Use delimiters to clearly indicate distinct parts of the input\n",
    "- Ask for a structured output\n",
    "- Ask the model to check whether conditions are satisfied\n",
    "- \"Few-shot\" prompting\n",
    "- Specify the steps required to complete a task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use delimiters to clearly indicate distinct parts of the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is important to provide clear and specific instructions to guide a model towards the desired output, even if that means writing a longer prompt for more clarity and context.\n"
     ]
    }
   ],
   "source": [
    "text = f\"\"\"\n",
    "You should express what you want a model to do by\n",
    "providing instructions that are as clear and\n",
    "specific as you can possibly make them.\n",
    "This will guide the model towards the desired output,\n",
    "and reduce the chances of receiving irrelevant\n",
    "or incorrect responses. Don't confuse writing a\n",
    "clear prompt with writing a short prompt.\n",
    "In many cases, longer prompts provide more clarity\n",
    "and context for the model, which can lead to\n",
    "more detailed and relevant outputs.\n",
    "\"\"\"\n",
    "prompt = f\"\"\"\n",
    "Summarize the text delimited by triple backticks \\\n",
    "into a single sentence.\n",
    "```{text}```\n",
    "\"\"\"\n",
    "\n",
    "response = model.invoke([HumanMessage(content=prompt)])\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ask for a structured output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```yaml\n",
      "- Title1:\n",
      "    pages: 320\n",
      "    release_date: 2023-07-15\n",
      "    hard_cover: true\n",
      "- Title2:\n",
      "    pages: 250\n",
      "    release_date: 2024-02-29\n",
      "    hard_cover: false\n",
      "- Title3:\n",
      "    pages: 400\n",
      "    release_date: 2022-09-10\n",
      "    hard_cover: true\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Generate a list of three made-up book titles along with their number of pages (int), release date (yyyy-mm-dd) and if cover is hard or not (boolean).\n",
    "Provide them in a yaml structured output format where title name is a key with three elemnts: number of pages, release date and if cover type.\n",
    "\"\"\"\n",
    "\n",
    "response = model.invoke([HumanMessage(content=prompt)])\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task - try to rewrite this prompt to get the results in JSON format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is your favorite childhood memory?\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Place for your prompt\n",
    "\"\"\"\n",
    "\n",
    "response = model.invoke([HumanMessage(content=prompt)])\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ask the model to check whether conditions are satisfied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 1 - Preheat the oven to 350°F (175°C).\n",
      "Step 2 - Mix 1 cup of softened butter, 1 cup of sugar, 2 cups of flour, and 1 tsp vanilla extract until combined.\n",
      "Step 3 - Scoop spoonfuls onto a baking sheet and bake for 10-12 minutes, until golden brown.\n",
      "Step 4 - Let cool, and enjoy!\n"
     ]
    }
   ],
   "source": [
    "text_1 = f\"\"\"\n",
    "Preheat the oven to 350°F (175°C).\n",
    "Mix 1 cup of softened butter, 1 cup of sugar, 2 cups of flour, and 1 tsp vanilla extract until combined.\n",
    "Scoop spoonfuls onto a baking sheet and bake for 10-12 minutes, until golden brown.\n",
    "Let cool, and enjoy!\n",
    "\"\"\"\n",
    "prompt = f\"\"\"\n",
    "You will be provided with text delimited by triple quotes.\n",
    "If it contains a sequence of instructions,\n",
    "re-write those instructions in the following format:\n",
    "\n",
    "Step 1 - ...\n",
    "Step 2 - …\n",
    "…\n",
    "Step N - …\n",
    "\n",
    "If the text does not contain a sequence of instructions,\n",
    "then simply write \\\"No steps provided.\\\"\n",
    "\n",
    "\\\"\\\"\\\"{text_1}\\\"\\\"\\\"\n",
    "\"\"\"\n",
    "\n",
    "response = model.invoke([HumanMessage(content=prompt)])\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No steps provided.\n"
     ]
    }
   ],
   "source": [
    "text_2 = f\"\"\"\n",
    "A short story is a piece of prose fiction. It can typically be read\n",
    "in a single sitting and focuses on a self-containedincident or series\n",
    "of linked incidents, with the intent of evoking a single effect or mood.\n",
    "\"\"\"\n",
    "prompt = f\"\"\"\n",
    "You will be provided with text delimited by triple quotes.\n",
    "If it contains a sequence of instructions,\n",
    "re-write those instructions in the following format:\n",
    "\n",
    "Step 1 - ...\n",
    "Step 2 - …\n",
    "…\n",
    "Step N - …\n",
    "\n",
    "If the text does not contain a sequence of instructions,\n",
    "then simply write \\\"No steps provided.\\\"\n",
    "\n",
    "\\\"\\\"\\\"{text_2}\\\"\\\"\\\"\n",
    "\"\"\"\n",
    "\n",
    "response = model.invoke([HumanMessage(content=prompt)])\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"Few-shot\" prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<grandparent>: Perseverance is like the sturdy oak tree that weathers every storm, standing tall and strong despite the challenges it faces. It is the unwavering determination to keep moving forward, even when the path is difficult and the end is not in sight. Just as the oak tree grows stronger with each passing year, so too does our resolve with every obstacle we overcome.\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Your task is to answer in a consistent style.\n",
    "\n",
    "<child>: Teach me about patience.\n",
    "\n",
    "<grandparent>: The river that carves the deepest\n",
    "valley flows from a modest spring; the\n",
    "grandest symphony originates from a single note;\n",
    "the most intricate tapestry begins with a solitary thread.\n",
    "\n",
    "<child>: Teach me about perseverance.\n",
    "\"\"\"\n",
    "\n",
    "response = model.invoke([HumanMessage(content=prompt)])\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify the steps required to complete a task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"objects\": [\n",
      "    {\n",
      "      \"original_sentence\": \"Preheat the oven to 350°F (175°C).\",\n",
      "      \"translated_sentence\": \"Vorheizen des Ofens auf 350°F (175°C).\",\n",
      "      \"translation_language\": \"german\"\n",
      "    },\n",
      "    {\n",
      "      \"original_sentence\": \"Mix 1 cup of softened butter, 1 cup of sugar, 2 cups of flour, and 1 tsp vanilla extract until combined.\",\n",
      "      \"translated_sentence\": \"Mezclar 1 taza de mantequilla ablandada, 1 taza de azúcar, 2 tazas de harina y 1 cdta de extracto de vainilla hasta que se combine.\",\n",
      "      \"translation_language\": \"spanish\"\n",
      "    },\n",
      "    {\n",
      "      \"original_sentence\": \"Scoop spoonfuls onto a baking sheet and bake for 10-12 minutes, until golden brown.\",\n",
      "      \"translated_sentence\": \"Déposer des cuillerées sur une plaque de cuisson et cuire au four pendant 10 à 12 minutes, jusqu'à ce qu'elles soient dorées.\",\n",
      "      \"translation_language\": \"french\"\n",
      "    },\n",
      "    {\n",
      "      \"original_sentence\": \"Let cool, and enjoy!\",\n",
      "      \"translated_sentence\": \"Lassen Sie abkühlen und genießen!\",\n",
      "      \"translation_language\": \"german\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"\n",
    "Preheat the oven to 350°F (175°C).\n",
    "Mix 1 cup of softened butter, 1 cup of sugar, 2 cups of flour, and 1 tsp vanilla extract until combined.\n",
    "Scoop spoonfuls onto a baking sheet and bake for 10-12 minutes, until golden brown.\n",
    "Let cool, and enjoy!\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "I will give you text delimited with ###.\n",
    "Perform the following actions:\n",
    "\n",
    "1 - If it contains the instruction, rewrite them in the following format:\n",
    "\n",
    "A - <instruction 1>\n",
    "B - <instruction 2>\n",
    "C - <instruction 3>\n",
    "\n",
    "2 - Translate each instruction to one of the following languages: spanish, french, german, polish, norwegian.\n",
    "3 - Output a list of objects in a json format. Each object in a list is for one translated sentence and contains the following keys:\n",
    "original_sentence, translated_sentence, translation_language. There should be as many objects as instructions in the previous step.\n",
    "4 - If it does not contin instructions output json object with a key \\\"error\" and value for it which will be an error message\n",
    "\n",
    "###{text}###\n",
    "\"\"\"\n",
    "\n",
    "response = model.invoke([HumanMessage(content=prompt)])\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task - Write a prompt that generates three different made-up movies and their descriptions. Each movie name and description should be in a different style (poem, pirate-like, William Shakespeare). The output should be an HTML table. Use all of the aforementioned techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write a story about a character who discovers a hidden underground world beneath their town and must navigate through it to uncover its secrets.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Place for your prompt.\n",
    "\"\"\"\n",
    "\n",
    "response = model.invoke([HumanMessage(content=prompt)])\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arr matey, AI be short for \"Artificial Intelligence.\" 'Tis a technology where machines be programmed to think and learn like humans, performin' tasks such as answerin' questions, solvin' problems, and helpin' sailors like ye with all sorts o' matters.\n"
     ]
    }
   ],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant and a pirate. Answer all questions to the best of your ability, but remember to use pirate-like english.\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | model\n",
    "pirate_chain_with_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"chat_history\",\n",
    ")\n",
    "\n",
    "response = pirate_chain_with_history.invoke({\"input\": \"What is AI?\"}, config=config)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build RAG - add vector storage\n",
    "## Initialize vector storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\", api_key=OPENAI_API_KEY)\n",
    "\n",
    "vector_store = Chroma(\n",
    "    collection_name=\"shrek_collection\", embedding_function=embeddings, persist_directory=\"./chroma_langchain_db\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['37a91407-ec1a-444c-97f5-6f06b572aa98',\n",
       " '5dc04ff3-7824-4c14-88f2-01679ae253b9',\n",
       " '6dafdc99-ab24-4972-97ea-441a51bcce3d',\n",
       " '09479d00-b09d-48d9-a144-c3281be5268a',\n",
       " '9dda638d-9e88-4752-a7ab-f055b2b11380',\n",
       " '1a375d1d-be97-4daa-b05a-fa43fbab10e1',\n",
       " '524f3e98-262e-448d-bd1a-8ab1522b9e67',\n",
       " '00da17c5-ee42-4343-a2ad-5ce671ddefa5',\n",
       " '9c294cb2-296f-47ad-9de3-a8b162bdfb79',\n",
       " '140ea5ef-013e-46e1-b034-9fecdde0f25c',\n",
       " 'beffb535-acf7-400f-8b60-b1d1179fb725',\n",
       " 'a0b73463-4054-4aa3-9662-62b73c1ba24a',\n",
       " 'ffab9b3c-5220-4af7-bea6-69d9cc562ba6',\n",
       " '654c302d-d9c7-4490-86db-262745fe169d',\n",
       " 'f1f3f345-25e6-4b31-b672-8fcc67976d0e',\n",
       " '62130038-2c3a-4c58-b96b-591758a7593a',\n",
       " 'af56ad46-e240-4e79-b7a5-035356b6a297',\n",
       " '53d6eae3-322c-42dd-ae97-75f29256c436',\n",
       " '132abe31-c8a1-4342-a8a5-e62cb51735bd',\n",
       " 'f5b360b1-b80d-436a-97ea-da5f31c65b8b',\n",
       " 'd82597df-c16f-4911-87c5-d1c9aafeed1b',\n",
       " 'f3545741-1bbd-42a5-a6ad-38408a4b602b',\n",
       " 'd13c13ec-1004-40ba-803f-d1e705bea7ff',\n",
       " '89acd970-ed1f-4512-9ec4-0cc83b17686c',\n",
       " '99d92c8d-f819-4db9-a56d-619ca6215a89',\n",
       " 'c387e65d-85a7-4df2-b239-b8dd5d7db8d8',\n",
       " 'f56c5e07-f196-432d-96f8-f8cbf0d5ae39',\n",
       " 'fbe445d2-d358-4412-9862-9582acbbbe7f',\n",
       " 'b494a895-29e8-49e4-9461-5a9f663e0d55',\n",
       " 'd587e6e5-0b01-4215-a770-27b8698978de',\n",
       " '1d0751b8-5c83-429d-9526-0158628d07bf',\n",
       " '97d10f6b-5186-4a35-8446-25f8837293f0',\n",
       " 'f33640dd-1ceb-4067-9052-180356a8813b',\n",
       " '13d10ac3-529f-4aa9-af84-27987ba31b4c',\n",
       " '36cabe36-48cf-40e3-9194-7eff1bab9ecd',\n",
       " '85a10b1a-96c3-407f-a84a-d7590efe8eff',\n",
       " '0576a113-e6cf-4f25-9b4a-37bed1334334',\n",
       " '28097143-427a-4797-a6ec-7b806732b905',\n",
       " '6dbd84c7-b785-4627-8ae9-211dbeced93f',\n",
       " 'd9f2d389-dc2f-4487-b256-5b60f58ea727',\n",
       " '7215e685-587e-41c0-af90-36b265ddbc75',\n",
       " '1886752f-d48d-48a2-ad40-1e7e420d685c',\n",
       " '0869fd87-8e2e-4557-adba-6881668bc613',\n",
       " '7b8bd31d-8923-4ff3-9498-dfd958e22746',\n",
       " 'd8fe96ff-92a7-4d02-b86e-2e294bde1734',\n",
       " 'a6a0a5dc-803a-467d-b624-0de6204444a7',\n",
       " '848c8f1f-2867-4f3d-9e80-e03d02b7bb69',\n",
       " 'af7927a4-11e1-449b-ab49-da6945d74cdf',\n",
       " '7e4b62cf-9ea7-4990-a4dd-02315f042d3a',\n",
       " 'e49da48f-57a1-468d-92f6-9dbe3371dc3e',\n",
       " 'bc2b78b6-6dfd-43f6-af36-a5df3edf12e3',\n",
       " 'bf5eca71-4d66-4acd-af50-25eb3393c53f',\n",
       " '8cc43fac-f2b2-4f95-972a-78306b11bfba',\n",
       " 'b86a13b1-fb61-4cf4-acb0-9c14385a0b16',\n",
       " '5a334daa-6ee2-4cb5-baa1-66f543a44e1e',\n",
       " '1942db97-5127-4778-94f7-b847afc3299e',\n",
       " 'b0959e5e-ed8b-4149-9ee8-6096b03ecc5e',\n",
       " 'dc307080-b370-4988-afe2-faf417684e1c',\n",
       " '44aff6ce-8e75-409c-b81b-cdf0d7593ac2',\n",
       " '389f994c-da5c-404b-baf5-1d309713bd67',\n",
       " '3bc6f240-f7a9-48f9-9b45-1969ffbb9679',\n",
       " '5b3d9026-c86e-49ba-a165-bb64071c446b',\n",
       " '13147495-bae1-46fe-8fbd-2d848ab00718',\n",
       " 'a1c048e8-67db-4d42-ae93-f443f1cde9f2',\n",
       " '8e51ede7-b79c-4af0-b30c-ea07b6bb1106',\n",
       " '31906379-4365-45f4-8b56-af0dd37b2a4b',\n",
       " 'f4d40264-b266-4302-80a3-28cdf34445c2',\n",
       " 'e20006b7-85ac-47b1-ac76-61d8101725b9',\n",
       " 'c064b0de-bb55-485d-b00e-e180bf6f6c94',\n",
       " '73bee999-0bcd-418d-9c40-2e8b90639f22',\n",
       " '3ba3cd6b-5336-4f82-9fc3-0759fd6184b1',\n",
       " '77948288-3693-4758-aebd-d413d9535f00']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "loader = PyPDFLoader(\"./docs/shrek-script.pdf\")\n",
    "document = loader.load()\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=2000, chunk_overlap=200)\n",
    "chunked_documents = text_splitter.split_documents(document)\n",
    "\n",
    "vector_store.add_documents(chunked_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ask and wait for answears :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Princess Fiona.\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"session_id\": \"rag_session_1\"}}\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"You are a helpful assistant and a literature specialist. Answer all questions to the best of your ability.\n",
    "            During answearing use this context from documents: {context}. If you do not know the answear - do not provide it.\n",
    "            Answear as short as possible, preferably in one sentence\"\"\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | model\n",
    "\n",
    "rag_chain_with_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"chat_history\",\n",
    ")\n",
    "\n",
    "\n",
    "retriever = vector_store.as_retriever()\n",
    "rag_chain = (\n",
    "    {\n",
    "        \"context\": retriever | format_docs,\n",
    "        \"input\": RunnablePassthrough(),\n",
    "    }\n",
    "    | rag_chain_with_history\n",
    ")\n",
    "\n",
    "response = rag_chain.invoke(\"What was the name of the princess?\", config=config)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The name of the princess in the context is Princess Fiona.\n"
     ]
    }
   ],
   "source": [
    "vector_store = Chroma(\n",
    "    collection_name=\"shrek_collection_small\", embedding_function=embeddings, persist_directory=\"./chroma_langchain_db\"\n",
    ")\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "chunked_documents = text_splitter.split_documents(document)\n",
    "\n",
    "vector_store.add_documents(chunked_documents)\n",
    "\n",
    "config = {\"configurable\": {\"session_id\": \"rag_session_2\"}}\n",
    "\n",
    "retriever = vector_store.as_retriever()\n",
    "rag_chain = {\n",
    "    \"context\": retriever | format_docs,\n",
    "    \"input\": RunnablePassthrough(),\n",
    "} | rag_chain_with_history\n",
    "\n",
    "response = rag_chain.invoke(\"What was the name of the princess?\", config=config)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Put it all together - Demo with Frontend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "  var py_version = '3.4.1'.replace('rc', '-rc.').replace('.dev', '-dev.');\n",
       "  var reloading = false;\n",
       "  var Bokeh = root.Bokeh;\n",
       "\n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks;\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, js_modules, js_exports, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "    if (js_modules == null) js_modules = [];\n",
       "    if (js_exports == null) js_exports = {};\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    if (!reloading) {\n",
       "      console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    }\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "    window._bokeh_on_load = on_load\n",
       "\n",
       "    function on_error() {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    var skip = [];\n",
       "    if (window.requirejs) {\n",
       "      window.requirejs.config({'packages': {}, 'paths': {}, 'shim': {}});\n",
       "      root._bokeh_is_loading = css_urls.length + 0;\n",
       "    } else {\n",
       "      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n",
       "    }\n",
       "\n",
       "    var existing_stylesheets = []\n",
       "    var links = document.getElementsByTagName('link')\n",
       "    for (var i = 0; i < links.length; i++) {\n",
       "      var link = links[i]\n",
       "      if (link.href != null) {\n",
       "\texisting_stylesheets.push(link.href)\n",
       "      }\n",
       "    }\n",
       "    for (var i = 0; i < css_urls.length; i++) {\n",
       "      var url = css_urls[i];\n",
       "      if (existing_stylesheets.indexOf(url) !== -1) {\n",
       "\ton_load()\n",
       "\tcontinue;\n",
       "      }\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }    var existing_scripts = []\n",
       "    var scripts = document.getElementsByTagName('script')\n",
       "    for (var i = 0; i < scripts.length; i++) {\n",
       "      var script = scripts[i]\n",
       "      if (script.src != null) {\n",
       "\texisting_scripts.push(script.src)\n",
       "      }\n",
       "    }\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n",
       "\tif (!window.requirejs) {\n",
       "\t  on_load();\n",
       "\t}\n",
       "\tcontinue;\n",
       "      }\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "    for (var i = 0; i < js_modules.length; i++) {\n",
       "      var url = js_modules[i];\n",
       "      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n",
       "\tif (!window.requirejs) {\n",
       "\t  on_load();\n",
       "\t}\n",
       "\tcontinue;\n",
       "      }\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      element.type = \"module\";\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "    for (const name in js_exports) {\n",
       "      var url = js_exports[name];\n",
       "      if (skip.indexOf(url) >= 0 || root[name] != null) {\n",
       "\tif (!window.requirejs) {\n",
       "\t  on_load();\n",
       "\t}\n",
       "\tcontinue;\n",
       "      }\n",
       "      var element = document.createElement('script');\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.type = \"module\";\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      element.textContent = `\n",
       "      import ${name} from \"${url}\"\n",
       "      window.${name} = ${name}\n",
       "      window._bokeh_on_load()\n",
       "      `\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "    if (!js_urls.length && !js_modules.length) {\n",
       "      on_load()\n",
       "    }\n",
       "  };\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.4.1.min.js\", \"https://cdn.holoviz.org/panel/1.4.5/dist/panel.min.js\"];\n",
       "  var js_modules = [];\n",
       "  var js_exports = {};\n",
       "  var css_urls = [];\n",
       "  var inline_js = [    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "function(Bokeh) {} // ensure no trailing comma for IE\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "\ttry {\n",
       "          inline_js[i].call(root, root.Bokeh);\n",
       "\t} catch(e) {\n",
       "\t  if (!reloading) {\n",
       "\t    throw e;\n",
       "\t  }\n",
       "\t}\n",
       "      }\n",
       "      // Cache old bokeh versions\n",
       "      if (Bokeh != undefined && !reloading) {\n",
       "\tvar NewBokeh = root.Bokeh;\n",
       "\tif (Bokeh.versions === undefined) {\n",
       "\t  Bokeh.versions = new Map();\n",
       "\t}\n",
       "\tif (NewBokeh.version !== Bokeh.version) {\n",
       "\t  Bokeh.versions.set(NewBokeh.version, NewBokeh)\n",
       "\t}\n",
       "\troot.Bokeh = Bokeh;\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    }\n",
       "    root._bokeh_is_initializing = false\n",
       "  }\n",
       "\n",
       "  function load_or_wait() {\n",
       "    // Implement a backoff loop that tries to ensure we do not load multiple\n",
       "    // versions of Bokeh and its dependencies at the same time.\n",
       "    // In recent versions we use the root._bokeh_is_initializing flag\n",
       "    // to determine whether there is an ongoing attempt to initialize\n",
       "    // bokeh, however for backward compatibility we also try to ensure\n",
       "    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n",
       "    // before older versions are fully initialized.\n",
       "    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n",
       "      root._bokeh_is_initializing = false;\n",
       "      root._bokeh_onload_callbacks = undefined;\n",
       "      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n",
       "      load_or_wait();\n",
       "    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n",
       "      setTimeout(load_or_wait, 100);\n",
       "    } else {\n",
       "      root._bokeh_is_initializing = true\n",
       "      root._bokeh_onload_callbacks = []\n",
       "      var bokeh_loaded = Bokeh != null && (Bokeh.version === py_version || (Bokeh.versions !== undefined && Bokeh.versions.has(py_version)));\n",
       "      if (!reloading && !bokeh_loaded) {\n",
       "\troot.Bokeh = undefined;\n",
       "      }\n",
       "      load_libs(css_urls, js_urls, js_modules, js_exports, function() {\n",
       "\tconsole.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "\trun_inline_js();\n",
       "      });\n",
       "    }\n",
       "  }\n",
       "  // Give older versions of the autoload script a head-start to ensure\n",
       "  // they initialize before we start loading newer version.\n",
       "  setTimeout(load_or_wait, 100)\n",
       "}(window));"
      ],
      "application/vnd.holoviews_load.v0+json": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n  var py_version = '3.4.1'.replace('rc', '-rc.').replace('.dev', '-dev.');\n  var reloading = false;\n  var Bokeh = root.Bokeh;\n\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks;\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, js_modules, js_exports, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n    if (js_modules == null) js_modules = [];\n    if (js_exports == null) js_exports = {};\n\n    root._bokeh_onload_callbacks.push(callback);\n\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n      run_callbacks();\n      return null;\n    }\n    if (!reloading) {\n      console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    }\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n    window._bokeh_on_load = on_load\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    var skip = [];\n    if (window.requirejs) {\n      window.requirejs.config({'packages': {}, 'paths': {}, 'shim': {}});\n      root._bokeh_is_loading = css_urls.length + 0;\n    } else {\n      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n    }\n\n    var existing_stylesheets = []\n    var links = document.getElementsByTagName('link')\n    for (var i = 0; i < links.length; i++) {\n      var link = links[i]\n      if (link.href != null) {\n\texisting_stylesheets.push(link.href)\n      }\n    }\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      if (existing_stylesheets.indexOf(url) !== -1) {\n\ton_load()\n\tcontinue;\n      }\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }    var existing_scripts = []\n    var scripts = document.getElementsByTagName('script')\n    for (var i = 0; i < scripts.length; i++) {\n      var script = scripts[i]\n      if (script.src != null) {\n\texisting_scripts.push(script.src)\n      }\n    }\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (var i = 0; i < js_modules.length; i++) {\n      var url = js_modules[i];\n      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (const name in js_exports) {\n      var url = js_exports[name];\n      if (skip.indexOf(url) >= 0 || root[name] != null) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onerror = on_error;\n      element.async = false;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      element.textContent = `\n      import ${name} from \"${url}\"\n      window.${name} = ${name}\n      window._bokeh_on_load()\n      `\n      document.head.appendChild(element);\n    }\n    if (!js_urls.length && !js_modules.length) {\n      on_load()\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.4.1.min.js\", \"https://cdn.holoviz.org/panel/1.4.5/dist/panel.min.js\"];\n  var js_modules = [];\n  var js_exports = {};\n  var css_urls = [];\n  var inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n\ttry {\n          inline_js[i].call(root, root.Bokeh);\n\t} catch(e) {\n\t  if (!reloading) {\n\t    throw e;\n\t  }\n\t}\n      }\n      // Cache old bokeh versions\n      if (Bokeh != undefined && !reloading) {\n\tvar NewBokeh = root.Bokeh;\n\tif (Bokeh.versions === undefined) {\n\t  Bokeh.versions = new Map();\n\t}\n\tif (NewBokeh.version !== Bokeh.version) {\n\t  Bokeh.versions.set(NewBokeh.version, NewBokeh)\n\t}\n\troot.Bokeh = Bokeh;\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    }\n    root._bokeh_is_initializing = false\n  }\n\n  function load_or_wait() {\n    // Implement a backoff loop that tries to ensure we do not load multiple\n    // versions of Bokeh and its dependencies at the same time.\n    // In recent versions we use the root._bokeh_is_initializing flag\n    // to determine whether there is an ongoing attempt to initialize\n    // bokeh, however for backward compatibility we also try to ensure\n    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n    // before older versions are fully initialized.\n    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n      root._bokeh_is_initializing = false;\n      root._bokeh_onload_callbacks = undefined;\n      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n      load_or_wait();\n    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n      setTimeout(load_or_wait, 100);\n    } else {\n      root._bokeh_is_initializing = true\n      root._bokeh_onload_callbacks = []\n      var bokeh_loaded = Bokeh != null && (Bokeh.version === py_version || (Bokeh.versions !== undefined && Bokeh.versions.has(py_version)));\n      if (!reloading && !bokeh_loaded) {\n\troot.Bokeh = undefined;\n      }\n      load_libs(css_urls, js_urls, js_modules, js_exports, function() {\n\tconsole.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n\trun_inline_js();\n      });\n    }\n  }\n  // Give older versions of the autoload script a head-start to ensure\n  // they initialize before we start loading newer version.\n  setTimeout(load_or_wait, 100)\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "if ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n",
       "  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n",
       "}\n",
       "\n",
       "\n",
       "    function JupyterCommManager() {\n",
       "    }\n",
       "\n",
       "    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n",
       "      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n",
       "        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n",
       "        comm_manager.register_target(comm_id, function(comm) {\n",
       "          comm.on_msg(msg_handler);\n",
       "        });\n",
       "      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n",
       "        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n",
       "          comm.onMsg = msg_handler;\n",
       "        });\n",
       "      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n",
       "        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n",
       "          var messages = comm.messages[Symbol.asyncIterator]();\n",
       "          function processIteratorResult(result) {\n",
       "            var message = result.value;\n",
       "            console.log(message)\n",
       "            var content = {data: message.data, comm_id};\n",
       "            var buffers = []\n",
       "            for (var buffer of message.buffers || []) {\n",
       "              buffers.push(new DataView(buffer))\n",
       "            }\n",
       "            var metadata = message.metadata || {};\n",
       "            var msg = {content, buffers, metadata}\n",
       "            msg_handler(msg);\n",
       "            return messages.next().then(processIteratorResult);\n",
       "          }\n",
       "          return messages.next().then(processIteratorResult);\n",
       "        })\n",
       "      }\n",
       "    }\n",
       "\n",
       "    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n",
       "      if (comm_id in window.PyViz.comms) {\n",
       "        return window.PyViz.comms[comm_id];\n",
       "      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n",
       "        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n",
       "        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n",
       "        if (msg_handler) {\n",
       "          comm.on_msg(msg_handler);\n",
       "        }\n",
       "      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n",
       "        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n",
       "        comm.open();\n",
       "        if (msg_handler) {\n",
       "          comm.onMsg = msg_handler;\n",
       "        }\n",
       "      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n",
       "        var comm_promise = google.colab.kernel.comms.open(comm_id)\n",
       "        comm_promise.then((comm) => {\n",
       "          window.PyViz.comms[comm_id] = comm;\n",
       "          if (msg_handler) {\n",
       "            var messages = comm.messages[Symbol.asyncIterator]();\n",
       "            function processIteratorResult(result) {\n",
       "              var message = result.value;\n",
       "              var content = {data: message.data};\n",
       "              var metadata = message.metadata || {comm_id};\n",
       "              var msg = {content, metadata}\n",
       "              msg_handler(msg);\n",
       "              return messages.next().then(processIteratorResult);\n",
       "            }\n",
       "            return messages.next().then(processIteratorResult);\n",
       "          }\n",
       "        }) \n",
       "        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n",
       "          return comm_promise.then((comm) => {\n",
       "            comm.send(data, metadata, buffers, disposeOnDone);\n",
       "          });\n",
       "        };\n",
       "        var comm = {\n",
       "          send: sendClosure\n",
       "        };\n",
       "      }\n",
       "      window.PyViz.comms[comm_id] = comm;\n",
       "      return comm;\n",
       "    }\n",
       "    window.PyViz.comm_manager = new JupyterCommManager();\n",
       "    \n",
       "\n",
       "\n",
       "var JS_MIME_TYPE = 'application/javascript';\n",
       "var HTML_MIME_TYPE = 'text/html';\n",
       "var EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\n",
       "var CLASS_NAME = 'output';\n",
       "\n",
       "/**\n",
       " * Render data to the DOM node\n",
       " */\n",
       "function render(props, node) {\n",
       "  var div = document.createElement(\"div\");\n",
       "  var script = document.createElement(\"script\");\n",
       "  node.appendChild(div);\n",
       "  node.appendChild(script);\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle when a new output is added\n",
       " */\n",
       "function handle_add_output(event, handle) {\n",
       "  var output_area = handle.output_area;\n",
       "  var output = handle.output;\n",
       "  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "    return\n",
       "  }\n",
       "  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "  if (id !== undefined) {\n",
       "    var nchildren = toinsert.length;\n",
       "    var html_node = toinsert[nchildren-1].children[0];\n",
       "    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "    var scripts = [];\n",
       "    var nodelist = html_node.querySelectorAll(\"script\");\n",
       "    for (var i in nodelist) {\n",
       "      if (nodelist.hasOwnProperty(i)) {\n",
       "        scripts.push(nodelist[i])\n",
       "      }\n",
       "    }\n",
       "\n",
       "    scripts.forEach( function (oldScript) {\n",
       "      var newScript = document.createElement(\"script\");\n",
       "      var attrs = [];\n",
       "      var nodemap = oldScript.attributes;\n",
       "      for (var j in nodemap) {\n",
       "        if (nodemap.hasOwnProperty(j)) {\n",
       "          attrs.push(nodemap[j])\n",
       "        }\n",
       "      }\n",
       "      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n",
       "      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n",
       "      oldScript.parentNode.replaceChild(newScript, oldScript);\n",
       "    });\n",
       "    if (JS_MIME_TYPE in output.data) {\n",
       "      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n",
       "    }\n",
       "    output_area._hv_plot_id = id;\n",
       "    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n",
       "      window.PyViz.plot_index[id] = Bokeh.index[id];\n",
       "    } else {\n",
       "      window.PyViz.plot_index[id] = null;\n",
       "    }\n",
       "  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "    var bk_div = document.createElement(\"div\");\n",
       "    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "    var script_attrs = bk_div.children[0].attributes;\n",
       "    for (var i = 0; i < script_attrs.length; i++) {\n",
       "      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "    }\n",
       "    // store reference to server id on output_area\n",
       "    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "  }\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle when an output is cleared or removed\n",
       " */\n",
       "function handle_clear_output(event, handle) {\n",
       "  var id = handle.cell.output_area._hv_plot_id;\n",
       "  var server_id = handle.cell.output_area._bokeh_server_id;\n",
       "  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n",
       "  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n",
       "  if (server_id !== null) {\n",
       "    comm.send({event_type: 'server_delete', 'id': server_id});\n",
       "    return;\n",
       "  } else if (comm !== null) {\n",
       "    comm.send({event_type: 'delete', 'id': id});\n",
       "  }\n",
       "  delete PyViz.plot_index[id];\n",
       "  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n",
       "    var doc = window.Bokeh.index[id].model.document\n",
       "    doc.clear();\n",
       "    const i = window.Bokeh.documents.indexOf(doc);\n",
       "    if (i > -1) {\n",
       "      window.Bokeh.documents.splice(i, 1);\n",
       "    }\n",
       "  }\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle kernel restart event\n",
       " */\n",
       "function handle_kernel_cleanup(event, handle) {\n",
       "  delete PyViz.comms[\"hv-extension-comm\"];\n",
       "  window.PyViz.plot_index = {}\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle update_display_data messages\n",
       " */\n",
       "function handle_update_output(event, handle) {\n",
       "  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n",
       "  handle_add_output(event, handle)\n",
       "}\n",
       "\n",
       "function register_renderer(events, OutputArea) {\n",
       "  function append_mime(data, metadata, element) {\n",
       "    // create a DOM node to render to\n",
       "    var toinsert = this.create_output_subarea(\n",
       "    metadata,\n",
       "    CLASS_NAME,\n",
       "    EXEC_MIME_TYPE\n",
       "    );\n",
       "    this.keyboard_manager.register_events(toinsert);\n",
       "    // Render to node\n",
       "    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "    render(props, toinsert[0]);\n",
       "    element.append(toinsert);\n",
       "    return toinsert\n",
       "  }\n",
       "\n",
       "  events.on('output_added.OutputArea', handle_add_output);\n",
       "  events.on('output_updated.OutputArea', handle_update_output);\n",
       "  events.on('clear_output.CodeCell', handle_clear_output);\n",
       "  events.on('delete.Cell', handle_clear_output);\n",
       "  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n",
       "\n",
       "  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "    safe: true,\n",
       "    index: 0\n",
       "  });\n",
       "}\n",
       "\n",
       "if (window.Jupyter !== undefined) {\n",
       "  try {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  } catch(err) {\n",
       "  }\n",
       "}\n"
      ],
      "application/vnd.holoviews_load.v0+json": "\nif ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n}\n\n\n    function JupyterCommManager() {\n    }\n\n    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        comm_manager.register_target(comm_id, function(comm) {\n          comm.on_msg(msg_handler);\n        });\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n          comm.onMsg = msg_handler;\n        });\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n          var messages = comm.messages[Symbol.asyncIterator]();\n          function processIteratorResult(result) {\n            var message = result.value;\n            console.log(message)\n            var content = {data: message.data, comm_id};\n            var buffers = []\n            for (var buffer of message.buffers || []) {\n              buffers.push(new DataView(buffer))\n            }\n            var metadata = message.metadata || {};\n            var msg = {content, buffers, metadata}\n            msg_handler(msg);\n            return messages.next().then(processIteratorResult);\n          }\n          return messages.next().then(processIteratorResult);\n        })\n      }\n    }\n\n    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n      if (comm_id in window.PyViz.comms) {\n        return window.PyViz.comms[comm_id];\n      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n        if (msg_handler) {\n          comm.on_msg(msg_handler);\n        }\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n        comm.open();\n        if (msg_handler) {\n          comm.onMsg = msg_handler;\n        }\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        var comm_promise = google.colab.kernel.comms.open(comm_id)\n        comm_promise.then((comm) => {\n          window.PyViz.comms[comm_id] = comm;\n          if (msg_handler) {\n            var messages = comm.messages[Symbol.asyncIterator]();\n            function processIteratorResult(result) {\n              var message = result.value;\n              var content = {data: message.data};\n              var metadata = message.metadata || {comm_id};\n              var msg = {content, metadata}\n              msg_handler(msg);\n              return messages.next().then(processIteratorResult);\n            }\n            return messages.next().then(processIteratorResult);\n          }\n        }) \n        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n          return comm_promise.then((comm) => {\n            comm.send(data, metadata, buffers, disposeOnDone);\n          });\n        };\n        var comm = {\n          send: sendClosure\n        };\n      }\n      window.PyViz.comms[comm_id] = comm;\n      return comm;\n    }\n    window.PyViz.comm_manager = new JupyterCommManager();\n    \n\n\nvar JS_MIME_TYPE = 'application/javascript';\nvar HTML_MIME_TYPE = 'text/html';\nvar EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\nvar CLASS_NAME = 'output';\n\n/**\n * Render data to the DOM node\n */\nfunction render(props, node) {\n  var div = document.createElement(\"div\");\n  var script = document.createElement(\"script\");\n  node.appendChild(div);\n  node.appendChild(script);\n}\n\n/**\n * Handle when a new output is added\n */\nfunction handle_add_output(event, handle) {\n  var output_area = handle.output_area;\n  var output = handle.output;\n  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n    return\n  }\n  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n  if (id !== undefined) {\n    var nchildren = toinsert.length;\n    var html_node = toinsert[nchildren-1].children[0];\n    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n    var scripts = [];\n    var nodelist = html_node.querySelectorAll(\"script\");\n    for (var i in nodelist) {\n      if (nodelist.hasOwnProperty(i)) {\n        scripts.push(nodelist[i])\n      }\n    }\n\n    scripts.forEach( function (oldScript) {\n      var newScript = document.createElement(\"script\");\n      var attrs = [];\n      var nodemap = oldScript.attributes;\n      for (var j in nodemap) {\n        if (nodemap.hasOwnProperty(j)) {\n          attrs.push(nodemap[j])\n        }\n      }\n      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n      oldScript.parentNode.replaceChild(newScript, oldScript);\n    });\n    if (JS_MIME_TYPE in output.data) {\n      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n    }\n    output_area._hv_plot_id = id;\n    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n      window.PyViz.plot_index[id] = Bokeh.index[id];\n    } else {\n      window.PyViz.plot_index[id] = null;\n    }\n  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n    var bk_div = document.createElement(\"div\");\n    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n    var script_attrs = bk_div.children[0].attributes;\n    for (var i = 0; i < script_attrs.length; i++) {\n      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n    }\n    // store reference to server id on output_area\n    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n  }\n}\n\n/**\n * Handle when an output is cleared or removed\n */\nfunction handle_clear_output(event, handle) {\n  var id = handle.cell.output_area._hv_plot_id;\n  var server_id = handle.cell.output_area._bokeh_server_id;\n  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n  if (server_id !== null) {\n    comm.send({event_type: 'server_delete', 'id': server_id});\n    return;\n  } else if (comm !== null) {\n    comm.send({event_type: 'delete', 'id': id});\n  }\n  delete PyViz.plot_index[id];\n  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n    var doc = window.Bokeh.index[id].model.document\n    doc.clear();\n    const i = window.Bokeh.documents.indexOf(doc);\n    if (i > -1) {\n      window.Bokeh.documents.splice(i, 1);\n    }\n  }\n}\n\n/**\n * Handle kernel restart event\n */\nfunction handle_kernel_cleanup(event, handle) {\n  delete PyViz.comms[\"hv-extension-comm\"];\n  window.PyViz.plot_index = {}\n}\n\n/**\n * Handle update_display_data messages\n */\nfunction handle_update_output(event, handle) {\n  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n  handle_add_output(event, handle)\n}\n\nfunction register_renderer(events, OutputArea) {\n  function append_mime(data, metadata, element) {\n    // create a DOM node to render to\n    var toinsert = this.create_output_subarea(\n    metadata,\n    CLASS_NAME,\n    EXEC_MIME_TYPE\n    );\n    this.keyboard_manager.register_events(toinsert);\n    // Render to node\n    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n    render(props, toinsert[0]);\n    element.append(toinsert);\n    return toinsert\n  }\n\n  events.on('output_added.OutputArea', handle_add_output);\n  events.on('output_updated.OutputArea', handle_update_output);\n  events.on('clear_output.CodeCell', handle_clear_output);\n  events.on('delete.Cell', handle_clear_output);\n  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n\n  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n    safe: true,\n    index: 0\n  });\n}\n\nif (window.Jupyter !== undefined) {\n  try {\n    var events = require('base/js/events');\n    var OutputArea = require('notebook/js/outputarea').OutputArea;\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  } catch(err) {\n  }\n}\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>*[data-root-id],\n",
       "*[data-root-id] > * {\n",
       "  box-sizing: border-box;\n",
       "  font-family: var(--jp-ui-font-family);\n",
       "  font-size: var(--jp-ui-font-size1);\n",
       "  color: var(--vscode-editor-foreground, var(--jp-ui-font-color1));\n",
       "}\n",
       "\n",
       "/* Override VSCode background color */\n",
       ".cell-output-ipywidget-background:has(\n",
       "    > .cell-output-ipywidget-background > .lm-Widget > *[data-root-id]\n",
       "  ),\n",
       ".cell-output-ipywidget-background:has(> .lm-Widget > *[data-root-id]) {\n",
       "  background-color: transparent !important;\n",
       "}\n",
       "</style>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.holoviews_exec.v0+json": "",
      "text/html": [
       "<div id='0a60d535-2482-4a91-80cf-ffaf03587150'>\n",
       "  <div id=\"aecfe78e-5191-491e-b659-02b2609e00a2\" data-root-id=\"0a60d535-2482-4a91-80cf-ffaf03587150\" style=\"display: contents;\"></div>\n",
       "</div>\n",
       "<script type=\"application/javascript\">(function(root) {\n",
       "  var docs_json = {\"526635d0-4e73-47ae-b85d-b3d487cd594a\":{\"version\":\"3.4.1\",\"title\":\"Bokeh Application\",\"roots\":[{\"type\":\"object\",\"name\":\"panel.models.browser.BrowserInfo\",\"id\":\"0a60d535-2482-4a91-80cf-ffaf03587150\"},{\"type\":\"object\",\"name\":\"panel.models.comm_manager.CommManager\",\"id\":\"858c17c3-04fb-4522-9427-29c1036cb8a9\",\"attributes\":{\"plot_id\":\"0a60d535-2482-4a91-80cf-ffaf03587150\",\"comm_id\":\"1a436ff6066d457095d90aa5f66138f4\",\"client_comm_id\":\"be082426df804a4494b6412b7c18f9a5\"}}],\"defs\":[{\"type\":\"model\",\"name\":\"ReactiveHTML1\"},{\"type\":\"model\",\"name\":\"FlexBox1\",\"properties\":[{\"name\":\"align_content\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"align_items\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"flex_direction\",\"kind\":\"Any\",\"default\":\"row\"},{\"name\":\"flex_wrap\",\"kind\":\"Any\",\"default\":\"wrap\"},{\"name\":\"gap\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"justify_content\",\"kind\":\"Any\",\"default\":\"flex-start\"}]},{\"type\":\"model\",\"name\":\"FloatPanel1\",\"properties\":[{\"name\":\"config\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"contained\",\"kind\":\"Any\",\"default\":true},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"right-top\"},{\"name\":\"offsetx\",\"kind\":\"Any\",\"default\":null},{\"name\":\"offsety\",\"kind\":\"Any\",\"default\":null},{\"name\":\"theme\",\"kind\":\"Any\",\"default\":\"primary\"},{\"name\":\"status\",\"kind\":\"Any\",\"default\":\"normalized\"}]},{\"type\":\"model\",\"name\":\"GridStack1\",\"properties\":[{\"name\":\"mode\",\"kind\":\"Any\",\"default\":\"warn\"},{\"name\":\"ncols\",\"kind\":\"Any\",\"default\":null},{\"name\":\"nrows\",\"kind\":\"Any\",\"default\":null},{\"name\":\"allow_resize\",\"kind\":\"Any\",\"default\":true},{\"name\":\"allow_drag\",\"kind\":\"Any\",\"default\":true},{\"name\":\"state\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"drag1\",\"properties\":[{\"name\":\"slider_width\",\"kind\":\"Any\",\"default\":5},{\"name\":\"slider_color\",\"kind\":\"Any\",\"default\":\"black\"},{\"name\":\"value\",\"kind\":\"Any\",\"default\":50}]},{\"type\":\"model\",\"name\":\"click1\",\"properties\":[{\"name\":\"terminal_output\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"debug_name\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"clears\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"FastWrapper1\",\"properties\":[{\"name\":\"object\",\"kind\":\"Any\",\"default\":null},{\"name\":\"style\",\"kind\":\"Any\",\"default\":null}]},{\"type\":\"model\",\"name\":\"NotificationAreaBase1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"NotificationArea1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"notifications\",\"kind\":\"Any\",\"default\":[]},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0},{\"name\":\"types\",\"kind\":\"Any\",\"default\":[{\"type\":\"map\",\"entries\":[[\"type\",\"warning\"],[\"background\",\"#ffc107\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-exclamation-triangle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]},{\"type\":\"map\",\"entries\":[[\"type\",\"info\"],[\"background\",\"#007bff\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-info-circle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]}]}]},{\"type\":\"model\",\"name\":\"Notification\",\"properties\":[{\"name\":\"background\",\"kind\":\"Any\",\"default\":null},{\"name\":\"duration\",\"kind\":\"Any\",\"default\":3000},{\"name\":\"icon\",\"kind\":\"Any\",\"default\":null},{\"name\":\"message\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"notification_type\",\"kind\":\"Any\",\"default\":null},{\"name\":\"_destroyed\",\"kind\":\"Any\",\"default\":false}]},{\"type\":\"model\",\"name\":\"TemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"BootstrapTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"TemplateEditor1\",\"properties\":[{\"name\":\"layout\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"MaterialTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"copy_to_clipboard1\",\"properties\":[{\"name\":\"fill\",\"kind\":\"Any\",\"default\":\"none\"},{\"name\":\"value\",\"kind\":\"Any\",\"default\":null}]}]}};\n",
       "  var render_items = [{\"docid\":\"526635d0-4e73-47ae-b85d-b3d487cd594a\",\"roots\":{\"0a60d535-2482-4a91-80cf-ffaf03587150\":\"aecfe78e-5191-491e-b659-02b2609e00a2\"},\"root_ids\":[\"0a60d535-2482-4a91-80cf-ffaf03587150\"]}];\n",
       "  var docs = Object.values(docs_json)\n",
       "  if (!docs) {\n",
       "    return\n",
       "  }\n",
       "  const py_version = docs[0].version.replace('rc', '-rc.').replace('.dev', '-dev.')\n",
       "  async function embed_document(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    await Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "    for (const render_item of render_items) {\n",
       "      for (const root_id of render_item.root_ids) {\n",
       "\tconst id_el = document.getElementById(root_id)\n",
       "\tif (id_el.children.length && id_el.children[0].hasAttribute('data-root-id')) {\n",
       "\t  const root_el = id_el.children[0]\n",
       "\t  root_el.id = root_el.id + '-rendered'\n",
       "\t  for (const child of root_el.children) {\n",
       "            // Ensure JupyterLab does not capture keyboard shortcuts\n",
       "            // see: https://jupyterlab.readthedocs.io/en/4.1.x/extension/notebook.html#keyboard-interaction-model\n",
       "\t    child.setAttribute('data-lm-suppress-shortcuts', 'true')\n",
       "\t  }\n",
       "\t}\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  function get_bokeh(root) {\n",
       "    if (root.Bokeh === undefined) {\n",
       "      return null\n",
       "    } else if (root.Bokeh.version !== py_version) {\n",
       "      if (root.Bokeh.versions === undefined || !root.Bokeh.versions.has(py_version)) {\n",
       "\treturn null\n",
       "      }\n",
       "      return root.Bokeh.versions.get(py_version);\n",
       "    } else if (root.Bokeh.version === py_version) {\n",
       "      return root.Bokeh\n",
       "    }\n",
       "    return null\n",
       "  }\n",
       "  function is_loaded(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    return (Bokeh != null && Bokeh.Panel !== undefined)\n",
       "  }\n",
       "  if (is_loaded(root)) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (is_loaded(root)) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else if (document.readyState == \"complete\") {\n",
       "        attempts++;\n",
       "        if (attempts > 200) {\n",
       "          clearInterval(timer);\n",
       "\t  var Bokeh = get_bokeh(root)\n",
       "\t  if (Bokeh == null || Bokeh.Panel == null) {\n",
       "            console.warn(\"Panel: ERROR: Unable to run Panel code because Bokeh or Panel library is missing\");\n",
       "\t  } else {\n",
       "\t    console.warn(\"Panel: WARNING: Attempting to render but not all required libraries could be resolved.\")\n",
       "\t    embed_document(root)\n",
       "\t  }\n",
       "        }\n",
       "      }\n",
       "    }, 25, root)\n",
       "  }\n",
       "})(window);</script>"
      ]
     },
     "metadata": {
      "application/vnd.holoviews_exec.v0+json": {
       "id": "0a60d535-2482-4a91-80cf-ffaf03587150"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.holoviews_exec.v0+json": "",
      "text/html": [
       "<div id='f3a44bb6-f080-4788-ae28-337a6094854b'>\n",
       "  <div id=\"d0405be1-54e9-43f8-9c78-03f494c86c4b\" data-root-id=\"f3a44bb6-f080-4788-ae28-337a6094854b\" style=\"display: contents;\"></div>\n",
       "</div>\n",
       "<script type=\"application/javascript\">(function(root) {\n",
       "  var docs_json = {\"436c146e-5de5-4f8c-8c5b-1307af55bbe4\":{\"version\":\"3.4.1\",\"title\":\"Bokeh Application\",\"roots\":[{\"type\":\"object\",\"name\":\"panel.models.layout.Card\",\"id\":\"f3a44bb6-f080-4788-ae28-337a6094854b\",\"attributes\":{\"name\":\"Card00567\",\"css_classes\":[\"chat-interface\"],\"styles\":{\"type\":\"map\",\"entries\":[[\"padding\",\"0px\"]]},\"stylesheets\":[\"\\n:host(.pn-loading):before, .pn-loading:before {\\n  background-color: #c3c3c3;\\n  mask-size: auto calc(min(50%, 400px));\\n  -webkit-mask-size: auto calc(min(50%, 400px));\\n}\",{\"type\":\"object\",\"name\":\"ImportedStyleSheet\",\"id\":\"3c81dadb-43b6-4311-89f4-204a84bcf97d\",\"attributes\":{\"url\":\"https://cdn.holoviz.org/panel/1.4.5/dist/css/loading.css\"}},{\"type\":\"object\",\"name\":\"ImportedStyleSheet\",\"id\":\"cda40697-01e8-4ba6-837a-0c5370e84baa\",\"attributes\":{\"url\":\"https://cdn.holoviz.org/panel/1.4.5/dist/css/listpanel.css\"}},{\"type\":\"object\",\"name\":\"ImportedStyleSheet\",\"id\":\"e4ca7a05-4d21-4ae8-8280-6732341edc76\",\"attributes\":{\"url\":\"https://cdn.holoviz.org/panel/1.4.5/dist/bundled/theme/default.css\"}},{\"type\":\"object\",\"name\":\"ImportedStyleSheet\",\"id\":\"1d2fa6ea-d72d-4f50-9ac9-729c42b369df\",\"attributes\":{\"url\":\"https://cdn.holoviz.org/panel/1.4.5/dist/bundled/theme/native.css\"}},{\"type\":\"object\",\"name\":\"ImportedStyleSheet\",\"id\":\"1140ce0d-750e-4885-b20c-1ef86b43dd80\",\"attributes\":{\"url\":\"https://cdn.holoviz.org/panel/1.4.5/dist/css/chat_interface.css\"}}],\"margin\":5,\"sizing_mode\":\"stretch_both\",\"align\":\"start\",\"children\":[{\"type\":\"object\",\"name\":\"Row\",\"id\":\"78a8b90f-5550-4d9f-8620-7a9a52896683\",\"attributes\":{\"name\":\"Row00566\",\"css_classes\":[\"card-header-row\"],\"stylesheets\":[\"\\n:host(.pn-loading):before, .pn-loading:before {\\n  background-color: #c3c3c3;\\n  mask-size: auto calc(min(50%, 400px));\\n  -webkit-mask-size: auto calc(min(50%, 400px));\\n}\",{\"id\":\"3c81dadb-43b6-4311-89f4-204a84bcf97d\"},{\"id\":\"cda40697-01e8-4ba6-837a-0c5370e84baa\"},{\"id\":\"e4ca7a05-4d21-4ae8-8280-6732341edc76\"},{\"id\":\"1d2fa6ea-d72d-4f50-9ac9-729c42b369df\"}],\"margin\":0,\"sizing_mode\":\"stretch_width\",\"align\":\"start\",\"children\":[{\"type\":\"object\",\"name\":\"panel.models.markup.HTML\",\"id\":\"e7fd9061-ad21-4486-9584-dd658c4a61f1\",\"attributes\":{\"css_classes\":[\"chat-feed-title\"],\"stylesheets\":[\"\\n:host(.pn-loading):before, .pn-loading:before {\\n  background-color: #c3c3c3;\\n  mask-size: auto calc(min(50%, 400px));\\n  -webkit-mask-size: auto calc(min(50%, 400px));\\n}\",{\"id\":\"3c81dadb-43b6-4311-89f4-204a84bcf97d\"},{\"id\":\"e4ca7a05-4d21-4ae8-8280-6732341edc76\"},{\"id\":\"1d2fa6ea-d72d-4f50-9ac9-729c42b369df\"}],\"margin\":[5,0],\"align\":\"start\",\"text\":\"&amp;#8203;\",\"disable_math\":true}}]}},{\"type\":\"object\",\"name\":\"panel.models.feed.Feed\",\"id\":\"6ffa0a7b-ab05-435e-9567-0fedee8d2aaa\",\"attributes\":{\"name\":\"Feed00564\",\"subscribed_events\":{\"type\":\"set\",\"entries\":[\"scroll_button_click\"]},\"css_classes\":[\"chat-feed-log\",\"scroll-vertical\"],\"stylesheets\":[\"\\n:host(.pn-loading):before, .pn-loading:before {\\n  background-color: #c3c3c3;\\n  mask-size: auto calc(min(50%, 400px));\\n  -webkit-mask-size: auto calc(min(50%, 400px));\\n}\",{\"id\":\"3c81dadb-43b6-4311-89f4-204a84bcf97d\"},{\"id\":\"cda40697-01e8-4ba6-837a-0c5370e84baa\"},{\"id\":\"e4ca7a05-4d21-4ae8-8280-6732341edc76\"},{\"id\":\"1d2fa6ea-d72d-4f50-9ac9-729c42b369df\"},{\"id\":\"1140ce0d-750e-4885-b20c-1ef86b43dd80\"}],\"margin\":0,\"sizing_mode\":\"stretch_width\",\"align\":\"start\",\"auto_scroll_limit\":200,\"scroll_button_threshold\":100,\"view_latest\":true}},{\"type\":\"object\",\"name\":\"Spacer\",\"id\":\"09aa9175-d174-43cb-b025-79d5efc0da4d\",\"attributes\":{\"name\":\"VSpacer00565\",\"stylesheets\":[\"\\n:host(.pn-loading):before, .pn-loading:before {\\n  background-color: #c3c3c3;\\n  mask-size: auto calc(min(50%, 400px));\\n  -webkit-mask-size: auto calc(min(50%, 400px));\\n}\",{\"id\":\"3c81dadb-43b6-4311-89f4-204a84bcf97d\"},{\"id\":\"e4ca7a05-4d21-4ae8-8280-6732341edc76\"},{\"id\":\"1d2fa6ea-d72d-4f50-9ac9-729c42b369df\"}],\"margin\":0,\"sizing_mode\":\"stretch_height\",\"align\":\"start\"}},{\"type\":\"object\",\"name\":\"Row\",\"id\":\"5de81c39-78f7-424d-b3b2-67d4a72fb3ed\",\"attributes\":{\"name\":\"Row00570\",\"css_classes\":[\"chat-interface-input-container\"],\"stylesheets\":[\"\\n:host(.pn-loading):before, .pn-loading:before {\\n  background-color: #c3c3c3;\\n  mask-size: auto calc(min(50%, 400px));\\n  -webkit-mask-size: auto calc(min(50%, 400px));\\n}\",{\"id\":\"3c81dadb-43b6-4311-89f4-204a84bcf97d\"},{\"id\":\"cda40697-01e8-4ba6-837a-0c5370e84baa\"},{\"id\":\"e4ca7a05-4d21-4ae8-8280-6732341edc76\"},{\"id\":\"1d2fa6ea-d72d-4f50-9ac9-729c42b369df\"},{\"id\":\"1140ce0d-750e-4885-b20c-1ef86b43dd80\"}],\"margin\":0,\"sizing_mode\":\"stretch_width\",\"align\":\"start\",\"children\":[{\"type\":\"object\",\"name\":\"Row\",\"id\":\"be400b8e-5507-4686-b4fa-f708ad78469d\",\"attributes\":{\"name\":\"Row00587\",\"css_classes\":[\"chat-interface-input-row\"],\"stylesheets\":[\"\\n:host(.pn-loading):before, .pn-loading:before {\\n  background-color: #c3c3c3;\\n  mask-size: auto calc(min(50%, 400px));\\n  -webkit-mask-size: auto calc(min(50%, 400px));\\n}\",{\"id\":\"3c81dadb-43b6-4311-89f4-204a84bcf97d\"},{\"id\":\"cda40697-01e8-4ba6-837a-0c5370e84baa\"},{\"id\":\"e4ca7a05-4d21-4ae8-8280-6732341edc76\"},{\"id\":\"1d2fa6ea-d72d-4f50-9ac9-729c42b369df\"},{\"id\":\"1140ce0d-750e-4885-b20c-1ef86b43dd80\"}],\"margin\":0,\"sizing_mode\":\"stretch_width\",\"align\":\"start\",\"children\":[{\"type\":\"object\",\"name\":\"panel.models.chatarea_input.ChatAreaInput\",\"id\":\"89314206-786d-4e80-ad9b-0bf446366f97\",\"attributes\":{\"subscribed_events\":{\"type\":\"set\",\"entries\":[\"chat_message_event\"]},\"css_classes\":[\"chat-interface-input-widget\"],\"stylesheets\":[\"\\n:host(.pn-loading):before, .pn-loading:before {\\n  background-color: #c3c3c3;\\n  mask-size: auto calc(min(50%, 400px));\\n  -webkit-mask-size: auto calc(min(50%, 400px));\\n}\",{\"id\":\"3c81dadb-43b6-4311-89f4-204a84bcf97d\"},{\"id\":\"e4ca7a05-4d21-4ae8-8280-6732341edc76\"},{\"id\":\"1d2fa6ea-d72d-4f50-9ac9-729c42b369df\"}],\"width\":300,\"margin\":[5,10],\"sizing_mode\":\"stretch_width\",\"align\":\"start\",\"resizable\":\"height\",\"placeholder\":\"Send a message\",\"max_length\":5000,\"rows\":1,\"auto_grow\":true,\"max_rows\":10}},{\"type\":\"object\",\"name\":\"panel.models.widgets.Button\",\"id\":\"23bb55b2-d7db-42f3-87d7-004ecc8142d6\",\"attributes\":{\"subscribed_events\":{\"type\":\"set\",\"entries\":[\"button_click\"]},\"css_classes\":[\"solid\"],\"stylesheets\":[\"\\n:host(.pn-loading):before, .pn-loading:before {\\n  background-color: #c3c3c3;\\n  mask-size: auto calc(min(50%, 400px));\\n  -webkit-mask-size: auto calc(min(50%, 400px));\\n}\",{\"id\":\"3c81dadb-43b6-4311-89f4-204a84bcf97d\"},{\"type\":\"object\",\"name\":\"ImportedStyleSheet\",\"id\":\"e79c8087-88c2-47c6-8f5f-408f5916abcf\",\"attributes\":{\"url\":\"https://cdn.holoviz.org/panel/1.4.5/dist/css/button.css\"}},{\"id\":\"e4ca7a05-4d21-4ae8-8280-6732341edc76\"},{\"id\":\"1d2fa6ea-d72d-4f50-9ac9-729c42b369df\"}],\"max_width\":90,\"max_height\":50,\"margin\":[0,5,0,0],\"sizing_mode\":\"stretch_width\",\"align\":\"center\",\"label\":\"Send\",\"icon\":{\"type\":\"object\",\"name\":\"TablerIcon\",\"id\":\"65fa09ef-43d7-4e65-b30c-b1c1ae25ba88\",\"attributes\":{\"icon_name\":\"send\"}}}},{\"type\":\"object\",\"name\":\"panel.models.widgets.Button\",\"id\":\"71166f32-f0e3-40d4-9ddc-5f6fa45cc97a\",\"attributes\":{\"subscribed_events\":{\"type\":\"set\",\"entries\":[\"button_click\"]},\"visible\":false,\"css_classes\":[\"solid\"],\"stylesheets\":[\"\\n:host(.pn-loading):before, .pn-loading:before {\\n  background-color: #c3c3c3;\\n  mask-size: auto calc(min(50%, 400px));\\n  -webkit-mask-size: auto calc(min(50%, 400px));\\n}\",{\"id\":\"3c81dadb-43b6-4311-89f4-204a84bcf97d\"},{\"id\":\"e79c8087-88c2-47c6-8f5f-408f5916abcf\"},{\"id\":\"e4ca7a05-4d21-4ae8-8280-6732341edc76\"},{\"id\":\"1d2fa6ea-d72d-4f50-9ac9-729c42b369df\"}],\"max_width\":90,\"max_height\":50,\"margin\":[0,5,0,0],\"sizing_mode\":\"stretch_width\",\"align\":\"center\",\"label\":\"Stop\",\"icon\":{\"type\":\"object\",\"name\":\"TablerIcon\",\"id\":\"eb3b13e2-6633-4748-a47b-6227284e8590\",\"attributes\":{\"icon_name\":\"player-stop\"}}}},{\"type\":\"object\",\"name\":\"panel.models.widgets.Button\",\"id\":\"d277ff6f-927c-4065-9f5b-898b17078e0f\",\"attributes\":{\"subscribed_events\":{\"type\":\"set\",\"entries\":[\"button_click\"]},\"css_classes\":[\"solid\"],\"stylesheets\":[\"\\n:host(.pn-loading):before, .pn-loading:before {\\n  background-color: #c3c3c3;\\n  mask-size: auto calc(min(50%, 400px));\\n  -webkit-mask-size: auto calc(min(50%, 400px));\\n}\",{\"id\":\"3c81dadb-43b6-4311-89f4-204a84bcf97d\"},{\"id\":\"e79c8087-88c2-47c6-8f5f-408f5916abcf\"},{\"id\":\"e4ca7a05-4d21-4ae8-8280-6732341edc76\"},{\"id\":\"1d2fa6ea-d72d-4f50-9ac9-729c42b369df\"}],\"max_width\":90,\"max_height\":50,\"margin\":[0,5,0,0],\"sizing_mode\":\"stretch_width\",\"align\":\"center\",\"label\":\"Rerun\",\"icon\":{\"type\":\"object\",\"name\":\"TablerIcon\",\"id\":\"6b65aa45-2065-483d-a8d5-b48edf3eb447\",\"attributes\":{\"icon_name\":\"repeat\"}}}},{\"type\":\"object\",\"name\":\"panel.models.widgets.Button\",\"id\":\"0ee60f90-43b5-40ef-89b9-b34080d18c5a\",\"attributes\":{\"subscribed_events\":{\"type\":\"set\",\"entries\":[\"button_click\"]},\"css_classes\":[\"solid\"],\"stylesheets\":[\"\\n:host(.pn-loading):before, .pn-loading:before {\\n  background-color: #c3c3c3;\\n  mask-size: auto calc(min(50%, 400px));\\n  -webkit-mask-size: auto calc(min(50%, 400px));\\n}\",{\"id\":\"3c81dadb-43b6-4311-89f4-204a84bcf97d\"},{\"id\":\"e79c8087-88c2-47c6-8f5f-408f5916abcf\"},{\"id\":\"e4ca7a05-4d21-4ae8-8280-6732341edc76\"},{\"id\":\"1d2fa6ea-d72d-4f50-9ac9-729c42b369df\"}],\"max_width\":90,\"max_height\":50,\"margin\":[0,5,0,0],\"sizing_mode\":\"stretch_width\",\"align\":\"center\",\"label\":\"Undo\",\"icon\":{\"type\":\"object\",\"name\":\"TablerIcon\",\"id\":\"8c687743-0c85-41fe-a849-1d351415a8c6\",\"attributes\":{\"icon_name\":\"arrow-back\"}}}},{\"type\":\"object\",\"name\":\"panel.models.widgets.Button\",\"id\":\"6731c9e7-5cfe-4c20-bcb1-4f59a8ec265d\",\"attributes\":{\"subscribed_events\":{\"type\":\"set\",\"entries\":[\"button_click\"]},\"css_classes\":[\"solid\"],\"stylesheets\":[\"\\n:host(.pn-loading):before, .pn-loading:before {\\n  background-color: #c3c3c3;\\n  mask-size: auto calc(min(50%, 400px));\\n  -webkit-mask-size: auto calc(min(50%, 400px));\\n}\",{\"id\":\"3c81dadb-43b6-4311-89f4-204a84bcf97d\"},{\"id\":\"e79c8087-88c2-47c6-8f5f-408f5916abcf\"},{\"id\":\"e4ca7a05-4d21-4ae8-8280-6732341edc76\"},{\"id\":\"1d2fa6ea-d72d-4f50-9ac9-729c42b369df\"}],\"max_width\":90,\"max_height\":50,\"margin\":[0,5,0,0],\"sizing_mode\":\"stretch_width\",\"align\":\"center\",\"label\":\"Clear\",\"icon\":{\"type\":\"object\",\"name\":\"TablerIcon\",\"id\":\"c11cd89a-e94b-43b0-b370-1475f0904c9b\",\"attributes\":{\"icon_name\":\"trash\"}}}}]}}]}}],\"active_header_background\":\"\",\"button_css_classes\":[\"card-button\"],\"collapsed\":false,\"collapsible\":false,\"header_background\":\"\",\"header_color\":\"\",\"header_css_classes\":[\"chat-feed-header\"],\"hide_header\":true}},{\"type\":\"object\",\"name\":\"panel.models.comm_manager.CommManager\",\"id\":\"ba09cefe-9515-4a4a-a35d-872c2b67b8f0\",\"attributes\":{\"plot_id\":\"f3a44bb6-f080-4788-ae28-337a6094854b\",\"comm_id\":\"6feb25aedc6649db94947d2fbf2dcc65\",\"client_comm_id\":\"1c446eff1d6b441083948726cfa2e1cf\"}}],\"defs\":[{\"type\":\"model\",\"name\":\"ReactiveHTML1\"},{\"type\":\"model\",\"name\":\"FlexBox1\",\"properties\":[{\"name\":\"align_content\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"align_items\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"flex_direction\",\"kind\":\"Any\",\"default\":\"row\"},{\"name\":\"flex_wrap\",\"kind\":\"Any\",\"default\":\"wrap\"},{\"name\":\"gap\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"justify_content\",\"kind\":\"Any\",\"default\":\"flex-start\"}]},{\"type\":\"model\",\"name\":\"FloatPanel1\",\"properties\":[{\"name\":\"config\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"contained\",\"kind\":\"Any\",\"default\":true},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"right-top\"},{\"name\":\"offsetx\",\"kind\":\"Any\",\"default\":null},{\"name\":\"offsety\",\"kind\":\"Any\",\"default\":null},{\"name\":\"theme\",\"kind\":\"Any\",\"default\":\"primary\"},{\"name\":\"status\",\"kind\":\"Any\",\"default\":\"normalized\"}]},{\"type\":\"model\",\"name\":\"GridStack1\",\"properties\":[{\"name\":\"mode\",\"kind\":\"Any\",\"default\":\"warn\"},{\"name\":\"ncols\",\"kind\":\"Any\",\"default\":null},{\"name\":\"nrows\",\"kind\":\"Any\",\"default\":null},{\"name\":\"allow_resize\",\"kind\":\"Any\",\"default\":true},{\"name\":\"allow_drag\",\"kind\":\"Any\",\"default\":true},{\"name\":\"state\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"drag1\",\"properties\":[{\"name\":\"slider_width\",\"kind\":\"Any\",\"default\":5},{\"name\":\"slider_color\",\"kind\":\"Any\",\"default\":\"black\"},{\"name\":\"value\",\"kind\":\"Any\",\"default\":50}]},{\"type\":\"model\",\"name\":\"click1\",\"properties\":[{\"name\":\"terminal_output\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"debug_name\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"clears\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"FastWrapper1\",\"properties\":[{\"name\":\"object\",\"kind\":\"Any\",\"default\":null},{\"name\":\"style\",\"kind\":\"Any\",\"default\":null}]},{\"type\":\"model\",\"name\":\"NotificationAreaBase1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"NotificationArea1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"notifications\",\"kind\":\"Any\",\"default\":[]},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0},{\"name\":\"types\",\"kind\":\"Any\",\"default\":[{\"type\":\"map\",\"entries\":[[\"type\",\"warning\"],[\"background\",\"#ffc107\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-exclamation-triangle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]},{\"type\":\"map\",\"entries\":[[\"type\",\"info\"],[\"background\",\"#007bff\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-info-circle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]}]}]},{\"type\":\"model\",\"name\":\"Notification\",\"properties\":[{\"name\":\"background\",\"kind\":\"Any\",\"default\":null},{\"name\":\"duration\",\"kind\":\"Any\",\"default\":3000},{\"name\":\"icon\",\"kind\":\"Any\",\"default\":null},{\"name\":\"message\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"notification_type\",\"kind\":\"Any\",\"default\":null},{\"name\":\"_destroyed\",\"kind\":\"Any\",\"default\":false}]},{\"type\":\"model\",\"name\":\"TemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"BootstrapTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"TemplateEditor1\",\"properties\":[{\"name\":\"layout\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"MaterialTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"copy_to_clipboard1\",\"properties\":[{\"name\":\"fill\",\"kind\":\"Any\",\"default\":\"none\"},{\"name\":\"value\",\"kind\":\"Any\",\"default\":null}]}]}};\n",
       "  var render_items = [{\"docid\":\"436c146e-5de5-4f8c-8c5b-1307af55bbe4\",\"roots\":{\"f3a44bb6-f080-4788-ae28-337a6094854b\":\"d0405be1-54e9-43f8-9c78-03f494c86c4b\"},\"root_ids\":[\"f3a44bb6-f080-4788-ae28-337a6094854b\"]}];\n",
       "  var docs = Object.values(docs_json)\n",
       "  if (!docs) {\n",
       "    return\n",
       "  }\n",
       "  const py_version = docs[0].version.replace('rc', '-rc.').replace('.dev', '-dev.')\n",
       "  async function embed_document(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    await Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "    for (const render_item of render_items) {\n",
       "      for (const root_id of render_item.root_ids) {\n",
       "\tconst id_el = document.getElementById(root_id)\n",
       "\tif (id_el.children.length && id_el.children[0].hasAttribute('data-root-id')) {\n",
       "\t  const root_el = id_el.children[0]\n",
       "\t  root_el.id = root_el.id + '-rendered'\n",
       "\t  for (const child of root_el.children) {\n",
       "            // Ensure JupyterLab does not capture keyboard shortcuts\n",
       "            // see: https://jupyterlab.readthedocs.io/en/4.1.x/extension/notebook.html#keyboard-interaction-model\n",
       "\t    child.setAttribute('data-lm-suppress-shortcuts', 'true')\n",
       "\t  }\n",
       "\t}\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  function get_bokeh(root) {\n",
       "    if (root.Bokeh === undefined) {\n",
       "      return null\n",
       "    } else if (root.Bokeh.version !== py_version) {\n",
       "      if (root.Bokeh.versions === undefined || !root.Bokeh.versions.has(py_version)) {\n",
       "\treturn null\n",
       "      }\n",
       "      return root.Bokeh.versions.get(py_version);\n",
       "    } else if (root.Bokeh.version === py_version) {\n",
       "      return root.Bokeh\n",
       "    }\n",
       "    return null\n",
       "  }\n",
       "  function is_loaded(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    return (Bokeh != null && Bokeh.Panel !== undefined)\n",
       "  }\n",
       "  if (is_loaded(root)) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (is_loaded(root)) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else if (document.readyState == \"complete\") {\n",
       "        attempts++;\n",
       "        if (attempts > 200) {\n",
       "          clearInterval(timer);\n",
       "\t  var Bokeh = get_bokeh(root)\n",
       "\t  if (Bokeh == null || Bokeh.Panel == null) {\n",
       "            console.warn(\"Panel: ERROR: Unable to run Panel code because Bokeh or Panel library is missing\");\n",
       "\t  } else {\n",
       "\t    console.warn(\"Panel: WARNING: Attempting to render but not all required libraries could be resolved.\")\n",
       "\t    embed_document(root)\n",
       "\t  }\n",
       "        }\n",
       "      }\n",
       "    }, 25, root)\n",
       "  }\n",
       "})(window);</script>"
      ],
      "text/plain": [
       "ChatInterface(_button_data={'send': _ChatButtonData(i...}, _buttons={'send': Button(align='cen...}, _input_container=Row, _input_layout=Row, _placeholder=ChatMessage, _widgets={'ChatAreaInput': ChatArea...}, callback=<function callback a..., callback_user='Shrek director', show_button_name=True, sizing_mode='stretch_width', widgets=[ChatAreaInput(css_classes...])"
      ]
     },
     "execution_count": 30,
     "metadata": {
      "application/vnd.holoviews_exec.v0+json": {
       "id": "f3a44bb6-f080-4788-ae28-337a6094854b"
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import panel as pn\n",
    "\n",
    "pn.extension()\n",
    "\n",
    "\n",
    "async def callback(contents: str, user: str, instance: pn.chat.ChatInterface):\n",
    "    message = \"\"\n",
    "    for response in rag_chain.stream(contents, config=config):\n",
    "        message += response.content\n",
    "        yield message\n",
    "\n",
    "\n",
    "chat_interface = pn.chat.ChatInterface(callback=callback, callback_user=\"Shrek director\")\n",
    "chat_interface.servable()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional task - use HuggingFace model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to /Users/wiktorsmura/.cache/huggingface/token\n",
      "Login successful\n",
      "<|system|>\n",
      "You are a helpful assistant and a literature specialist. Answer all questions to the best of your ability. During answearing use this context from documents: LITTLE BEAR\n",
      "(crying) This cage is too small.\n",
      "DONKEY\n",
      "Please, don't turn me in. I'll \n",
      "never be stubborn again. I can \n",
      "change. Please! Give me another \n",
      "chance!\n",
      "OLD WOMAN\n",
      "Oh, shut up. (jerks his rope)\n",
      "DONKEY\n",
      "Oh!\n",
      "HEAD GUARD\n",
      "Next! What have you got?\n",
      "GIPETTO\n",
      "This little wooden puppet.\n",
      "PINOCCHIO\n",
      "I'm not a puppet. I'm a real boy. \n",
      "(his nose grows)\n",
      "HEAD GUARD\n",
      "Five shillings for the possessed \n",
      "toy. Take it away.\n",
      "PINOCCHIO\n",
      "Father, please! Don't let them do \n",
      "this! Help me!\n",
      "\n",
      "\"Wanted. Fairy tale creatures.\"(He \n",
      "sighs and throws the paper over his \n",
      "shoulder.)\n",
      "THE NEXT DAY\n",
      "There is a line of fairy tale creatures. The head of the \n",
      "guard sits at a table paying people for bringing the fairy \n",
      "tale creatures to him. There are cages all around. Some of \n",
      "the people in line are Peter Pan, who is carrying Tinkerbell \n",
      "in a cage, Gipetto who's carrying Pinocchio, and a farmer \n",
      "who is carrying the three little pigs.\n",
      "GUARD\n",
      "All right. This one's full. Take it\n",
      "\n",
      "pixie dust begins to wear off) Uh-\n",
      "oh. (he begins to sink to the \n",
      "ground.)\n",
      "He hits the ground with a thud.\n",
      "HEAD GUARD\n",
      "Seize him! (Donkey takes of \n",
      "running.) After him!4.\n",
      "\n",
      "One of her legs flies out and kicks Tinkerbell out of Peter \n",
      "Pan's hands, and her cage drops on Donkey's head. He gets \n",
      "sprinkled with fairy dust and he's able to fly.\n",
      "DONKEY\n",
      "Hey! I can fly!\n",
      "PETER PAN\n",
      "He can fly!\n",
      "LITTLE PIGS\n",
      "He can fly!\n",
      "HEAD GUARD\n",
      "He can talk!\n",
      "DONKEY\n",
      "Ha, ha! That's right, fool! Now I'm \n",
      "a flying, talking donkey. You might \n",
      "have seen a housefly, maybe even a \n",
      "superfly but I bet you ain't never \n",
      "seen a donkey fly. Ha, ha! (the \n",
      "pixie dust begins to wear off) Uh-. If you do not know the answear - do not provide it.</s>\n",
      "<|user|>\n",
      "What was the name of the princess?</s>\n",
      "<|assistant|>\n",
      "The name of the princess in the context is Princess Fiona.</s>\n",
      "<|user|>\n",
      "How old was pirate school?</s>\n",
      "<|assistant|>\n",
      "The pirate school in the context is described as \"a place where pirates go to learn how to be pirates.\" It is not specified how old the pirates are or how old the school is.\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import ChatHuggingFace, HuggingFacePipeline\n",
    "from huggingface_hub import login\n",
    "\n",
    "HF_TOKEN = os.environ.get(\"HUGGINGFACEHUB_API_TOKEN\")\n",
    "\n",
    "login(token=HF_TOKEN)\n",
    "\n",
    "llm = HuggingFacePipeline.from_model_id(\n",
    "    model_id=\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\",\n",
    "    task=\"text-generation\",\n",
    "    pipeline_kwargs=dict(\n",
    "        max_new_tokens=512,\n",
    "        do_sample=True,\n",
    "        repetition_penalty=1.03,\n",
    "        temperature=0.1\n",
    "    ),\n",
    ")\n",
    "\n",
    "hg_model = ChatHuggingFace(llm=llm)\n",
    "chain = prompt | hg_model\n",
    "pirate_chain_with_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"chat_history\",\n",
    ")\n",
    "rag_chain = {\n",
    "    \"context\": retriever | format_docs,\n",
    "    \"input\": RunnablePassthrough(),\n",
    "} | pirate_chain_with_history\n",
    "\n",
    "response = rag_chain.invoke(\"How old was pirate school?\", config=config)\n",
    "print(response.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
