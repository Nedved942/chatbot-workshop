{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read OpenAI API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(\"secrets.env\")\n",
    "OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Call to OpenAI API\n",
    "\n",
    "**Pros of Using OpenAI Chat API in a Company's Chatbot:**\n",
    "\n",
    "1. **Advanced Natural Language Processing (NLP):** The API uses state-of-the-art NLP, allowing the chatbot to understand and respond to user queries more effectively, even with complex or ambiguous language.\n",
    "2. **Versatility:** OpenAI's API can handle a wide variety of topics, making the chatbot adaptable to diverse user needs across multiple domains without extensive retraining.\n",
    "3. **Scalability:** The API can handle high volumes of requests, enabling businesses to scale their chatbot solutions without worrying about performance degradation.\n",
    "4. **Continuous Improvement:** OpenAI continually updates and improves its models, so your chatbot can benefit from cutting-edge advancements in AI without needing significant internal resources.\n",
    "5. **Rapid Deployment:** Implementing the OpenAI Chat API can accelerate the development and deployment of a chatbot, reducing time-to-market compared to building a custom NLP system from scratch.\n",
    "\n",
    "**Cons of Using OpenAI Chat API in a Company's Chatbot:**\n",
    "\n",
    "1. **Cost:** Usage of the API incurs ongoing costs based on the volume of requests, which can add up, especially for high-traffic applications.\n",
    "2. **Limited Customization:** Although versatile, the API may not always meet highly specific business requirements, requiring additional layers of customization that can be complex to implement.\n",
    "3. **Data Privacy Concerns:** Using a third-party API may raise concerns about data privacy and security, particularly in industries that handle sensitive customer information.\n",
    "4. **Dependency on External Service:** Relying on an external service like OpenAI means potential downtime, rate-limiting, or API changes that are beyond the company's control.\n",
    "5. **Ethical Considerations:** AI-generated responses can sometimes produce unexpected or inappropriate content, which may require careful monitoring and mitigation strategies to maintain brand integrity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI, or Artificial Intelligence, refers to the simulation of human intelligence processes by machines, typically computer systems. This includes learning, reasoning, problem solving, perception, and language understanding. AI technologies include machine learning, natural language processing, computer vision, and robotics. AI is used in various applications, including self-driving cars, speech recognition, chatbots, medical diagnosis, and many others.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"What is AI?\",\n",
    "        }\n",
    "    ],\n",
    "    model=\"gpt-3.5-turbo\",\n",
    ")\n",
    "\n",
    "print(chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do I need to write utility classes on my own? - Utilise LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI, or artificial intelligence, refers to the simulation of human intelligence processes by machines, especially computer systems. These processes include learning, reasoning, problem-solving, perception, and language understanding. AI technologies are used to automate tasks, make predictions, and assist in decision-making across various industries and applications.\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-3.5-turbo\", api_key=OPENAI_API_KEY)\n",
    "response = model.invoke([HumanMessage(content=\"What is AI?\")])\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Of course! What specifically would you like to know more about?\n"
     ]
    }
   ],
   "source": [
    "response = model.invoke([HumanMessage(content=\"It is really interesting what you have written. Can you say more about it?\")])\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see - the model by itself doesn't remember the history of messages. We need to pass all messages to get the desired answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Of course! Artificial intelligence can be categorized into two main types: narrow AI and general AI. Narrow AI, also known as weak AI, is designed to perform specific tasks or solve specific problems, such as facial recognition, speech recognition, or autonomous vehicles. General AI, also known as strong AI, is a hypothetical form of AI that can understand, learn, and apply knowledge across a wide range of tasks â€“ essentially possessing human-like intelligence.\n",
      "\n",
      "AI technologies rely on various techniques, including machine learning, deep learning, natural language processing, and computer vision. Machine learning is a subset of AI that enables systems to learn from data and improve their performance without being explicitly programmed. Deep learning is a subset of machine learning that involves artificial neural networks inspired by the structure and function of the human brain.\n",
      "\n",
      "AI applications are vast and have been integrated into various industries, including healthcare, finance, transportation, and entertainment. Some common examples of AI in everyday life include virtual assistants like Siri and Alexa, recommendation systems on streaming platforms like Netflix, and predictive analytics in business operations.\n",
      "\n",
      "Despite the numerous benefits of AI, there are also ethical and societal concerns surrounding its development and deployment. Issues such as algorithm bias, job displacement, data privacy, and autonomous decision-making raise important questions about the responsible use of AI technology.\n",
      "\n",
      "Overall, AI continues to evolve rapidly and has the potential to revolutionize industries, enhance human capabilities, and shape the future of society.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "\n",
    "response = model.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"What is AI?\"),\n",
    "        AIMessage(\n",
    "            content=\"AI, or artificial intelligence, refers to the development of computer systems that can perform tasks that typically require human intelligence, such as visual perception, speech recognition, decision-making, and language translation. AI technology aims to mimic human cognitive functions and improve efficiency and accuracy in tasks that were previously only achievable by humans.\"\n",
    "        ),\n",
    "        HumanMessage(content=\"It is really interesting what you have written. Can you say more about it?\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Message History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.chat_history import (\n",
    "    BaseChatMessageHistory,\n",
    "    InMemoryChatMessageHistory,\n",
    ")\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "store = {}\n",
    "\n",
    "\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = InMemoryChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "\n",
    "chain_with_history = RunnableWithMessageHistory(model, get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parent run 18d1ab39-6cec-4f1d-ac20-623be21b31bd not found for run aed2acd9-be75-4596-bcfe-7b7f70df05d5. Treating as a root run.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI, or artificial intelligence, refers to the simulation of human intelligence in machines that are programmed to think and act like humans. This includes tasks such as learning, reasoning, problem-solving, perception, and language understanding. AI technologies are used in various applications such as virtual assistants, self-driving cars, medical diagnosis, and many others.\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"session_id\": \"session_1\"}}\n",
    "\n",
    "response = chain_with_history.invoke(\n",
    "    [HumanMessage(content=\"What is AI?\")],\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parent run e9b2683c-ebcb-41e4-bf30-0a2085b4d60a not found for run 349e05f7-c276-4cbf-9478-75a5801a8a6a. Treating as a root run.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Certainly! Artificial intelligence is a broad field that encompasses various subfields and technologies. Some of the key concepts and techniques used in AI include:\n",
      "\n",
      "1. Machine Learning: This is a subset of AI that involves developing algorithms that allow computers to learn from and make predictions or decisions based on data. Machine learning techniques include neural networks, deep learning, and reinforcement learning.\n",
      "\n",
      "2. Natural Language Processing (NLP): NLP is a branch of AI that focuses on enabling computers to understand, interpret, and generate human language. This technology is used in applications such as chatbots, language translation, and sentiment analysis.\n",
      "\n",
      "3. Computer Vision: Computer vision is the field of AI that enables machines to interpret and understand visual information from the real world. This technology is used in facial recognition, object detection, autonomous vehicles, and medical image analysis.\n",
      "\n",
      "4. Robotics: AI-powered robots are designed to perform tasks autonomously or with minimal human intervention. These robots can be used in manufacturing, healthcare, agriculture, and other industries to improve efficiency and productivity.\n",
      "\n",
      "5. Expert Systems: Expert systems are AI programs that simulate the knowledge and reasoning abilities of human experts in specific domains. These systems are used to provide expert advice, diagnose problems, and make decisions in various fields.\n",
      "\n",
      "Overall, AI technologies continue to advance rapidly and have the potential to revolutionize various industries and improve our daily lives in the future.\n"
     ]
    }
   ],
   "source": [
    "response = chain_with_history.invoke(\n",
    "    [HumanMessage(content=\"It is really interesting what you have written. Can you say more about it?\")],\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After a session_id change, another user will not have access to the previous conversation history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parent run ca97334c-89cf-4a21-96d0-67b14dfd16c7 not found for run 7f3ca574-f525-44d3-8ab3-03d9ae8c4ac7. Treating as a root run.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm sorry, but I do not have the ability to remember previous interactions or conversations. Can you please provide more context or details about what you were asking about earlier?\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"session_id\": \"session_2\"}}\n",
    "\n",
    "response = chain_with_history.invoke(\n",
    "    [HumanMessage(content=\"What was I asking about earlier?\")],\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different types of memories\n",
    "\n",
    "- all messages (presented earlier)\n",
    "- trim messages\n",
    "    - (+) helps to reduce context\n",
    "    - (-) older parts of conversation will be discarded and not passed to LLM\n",
    "- summarize conversation\n",
    "    - (+) helps to reduce context\n",
    "    - (-) some parts of conversation during summarization might be lost, but will better preserve older parts of conversation than trimming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trim messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parent run 075978dc-2121-4add-bfa6-0e22c41b6de6 not found for run 3629406b-e7da-44d4-b3e3-179671541d71. Treating as a root run.\n",
      "Parent run b7d81374-584f-494d-97ca-3afc66f554ed not found for run 9a728fdd-dff0-47cf-a5b3-a884ef0bf7d0. Treating as a root run.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: Hello Bob! How can I assist you today?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parent run 8b759e47-73e1-41cd-a70f-90adde3b8906 not found for run b3663c06-3075-48f4-8f30-e433ff846b10. Treating as a root run.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2: Your name is Bob. Is there anything else you would like to know or discuss?\n",
      "3: I'm sorry, I do not have the capability to know your name as I am an AI assistant.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "\n",
    "# Trim to four messages\n",
    "def trim_messages(chain_input):\n",
    "    current_store = store[config[\"configurable\"][\"session_id\"]]\n",
    "    if len(current_store.messages) <= 4:\n",
    "        return False\n",
    "\n",
    "    current_store.clear()\n",
    "\n",
    "    for message in current_store.messages[-4:]:\n",
    "        current_store.add_message(message)\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "chain_with_trimming = RunnablePassthrough.assign(messages_trimmed=trim_messages) | chain_with_history\n",
    "\n",
    "response = chain_with_trimming.invoke(\n",
    "    {\"input\": \"My name is Bob.\"},\n",
    "    config=config,\n",
    ")\n",
    "print(f\"1: {response.content}\")\n",
    "\n",
    "response = chain_with_trimming.invoke(\n",
    "    {\"input\": \"What is my name?\"},\n",
    "    config=config,\n",
    ")\n",
    "print(f\"2: {response.content}\")\n",
    "\n",
    "response = chain_with_trimming.invoke(\n",
    "    {\"input\": \"What is my name?\"},\n",
    "    config=config,\n",
    ")\n",
    "print(f\"3: {response.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarize conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parent run 97b320bd-4d1c-4dc9-b274-650501d3a932 not found for run 999d6deb-6afd-4384-bebb-18584a247880. Treating as a root run.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: Nice to meet you, Bob! How can I assist you today?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parent run 31c65c8d-ff19-4428-91f1-939174b3ee61 not found for run 175454ca-3f1f-4caa-9270-2fa5bb6e8036. Treating as a root run.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2: You introduced yourself as Bob.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parent run af22a2ae-6125-472d-a521-f352949e611a not found for run 98175ee6-bda5-435c-864f-ce3d861259d1. Treating as a root run.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3: You introduced yourself as \"Bob.\"\n",
      "[AIMessage(content='Bob introduced himself to the AI assistant as \"Bob,\" and the AI assistant welcomed him and offered assistance.', response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 75, 'total_tokens': 96}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-056f493d-d046-46a3-925d-dfff606b36f8-0', usage_metadata={'input_tokens': 75, 'output_tokens': 21, 'total_tokens': 96}), HumanMessage(content='With what name did I introduce myself?'), AIMessage(content='You introduced yourself as \"Bob.\"', response_metadata={'token_usage': {'completion_tokens': 7, 'prompt_tokens': 40, 'total_tokens': 47}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-98175ee6-bda5-435c-864f-ce3d861259d1-0', usage_metadata={'input_tokens': 40, 'output_tokens': 7, 'total_tokens': 47})]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "\n",
    "def summarize_messages(chain_input):\n",
    "    current_store = store[config[\"configurable\"][\"session_id\"]]\n",
    "    if len(current_store.messages) == 0:\n",
    "        return False\n",
    "\n",
    "    summarization_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "            (\n",
    "                \"user\",\n",
    "                \"Distill the above chat messages into a single summary message. Include as many specific details as you can.\",\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    summarization_chain = summarization_prompt | model\n",
    "    summary_message = summarization_chain.invoke({\"chat_history\": current_store.messages})\n",
    "\n",
    "    current_store.clear()\n",
    "    current_store.add_message(summary_message)\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "chain_with_summarization = RunnablePassthrough.assign(messages_summarized=summarize_messages) | chain_with_history\n",
    "\n",
    "response = chain_with_summarization.invoke(\n",
    "    {\"input\": \"My name is Bob.\"},\n",
    "    config=config,\n",
    ")\n",
    "print(f\"1: {response.content}\")\n",
    "\n",
    "response = chain_with_summarization.invoke(\n",
    "    {\"input\": \"With what name did I introduce myself?\"},\n",
    "    config=config,\n",
    ")\n",
    "print(f\"2: {response.content}\")\n",
    "\n",
    "response = chain_with_summarization.invoke(\n",
    "    {\"input\": \"With what name did I introduce myself?\"},\n",
    "    config=config,\n",
    ")\n",
    "print(f\"3: {response.content}\")\n",
    "print(store[config[\"configurable\"][\"session_id\"]].messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompting techniques\n",
    "\n",
    "- Use delimiters to clearly indicate distinct parts of the input\n",
    "- Ask for a structured output\n",
    "- Ask the model to check whether conditions are satisfied\n",
    "- \"Few-shot\" prompting\n",
    "- Specify the steps required to complete a task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use delimiters to clearly indicate distinct parts of the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clear and specific instructions should be provided to guide a model towards the desired output and reduce the chances of irrelevant or incorrect responses, emphasizing that longer prompts can provide more clarity and context for more detailed and relevant outputs.\n"
     ]
    }
   ],
   "source": [
    "text = f\"\"\"\n",
    "You should express what you want a model to do by\n",
    "providing instructions that are as clear and\n",
    "specific as you can possibly make them.\n",
    "This will guide the model towards the desired output,\n",
    "and reduce the chances of receiving irrelevant\n",
    "or incorrect responses. Don't confuse writing a\n",
    "clear prompt with writing a short prompt.\n",
    "In many cases, longer prompts provide more clarity\n",
    "and context for the model, which can lead to\n",
    "more detailed and relevant outputs.\n",
    "\"\"\"\n",
    "prompt = f\"\"\"\n",
    "Summarize the text delimited by triple backticks \\\n",
    "into a single sentence.\n",
    "```{text}```\n",
    "\"\"\"\n",
    "\n",
    "response = model.invoke([HumanMessage(content=prompt)])\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ask for a structured output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```yaml\n",
      "- Title 1:\n",
      "    - Number of pages: 320\n",
      "    - Release date: 2023-07-15\n",
      "    - Cover type: true\n",
      "- Title 2:\n",
      "    - Number of pages: 250\n",
      "    - Release date: 2024-02-29\n",
      "    - Cover type: false\n",
      "- Title 3:\n",
      "    - Number of pages: 400\n",
      "    - Release date: 2022-10-10\n",
      "    - Cover type: true\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Generate a list of three made-up book titles along with their number of pages (int), release date (yyyy-mm-dd) and if cover is hard or not (boolean).\n",
    "Provide them in a yaml structured output format where title name is a key with three elemnts: number of pages, release date and if cover type.\n",
    "\"\"\"\n",
    "\n",
    "response = model.invoke([HumanMessage(content=prompt)])\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task - try to rewrite this prompt to get the results in JSON format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is your favorite childhood memory and why?\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Place for your prompt\n",
    "\"\"\"\n",
    "\n",
    "response = model.invoke([HumanMessage(content=prompt)])\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ask the model to check whether conditions are satisfied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 1 - Preheat the oven to 350Â°F (175Â°C).\n",
      "Step 2 - Mix 1 cup of softened butter, 1 cup of sugar, 2 cups of flour, and 1 tsp vanilla extract until combined.\n",
      "Step 3 - Scoop spoonfuls onto a baking sheet and bake for 10-12 minutes, until golden brown.\n",
      "Step 4 - Let cool, and enjoy!\n"
     ]
    }
   ],
   "source": [
    "text_1 = f\"\"\"\n",
    "Preheat the oven to 350Â°F (175Â°C).\n",
    "Mix 1 cup of softened butter, 1 cup of sugar, 2 cups of flour, and 1 tsp vanilla extract until combined.\n",
    "Scoop spoonfuls onto a baking sheet and bake for 10-12 minutes, until golden brown.\n",
    "Let cool, and enjoy!\n",
    "\"\"\"\n",
    "prompt = f\"\"\"\n",
    "You will be provided with text delimited by triple quotes.\n",
    "If it contains a sequence of instructions,\n",
    "re-write those instructions in the following format:\n",
    "\n",
    "Step 1 - ...\n",
    "Step 2 - â€¦\n",
    "â€¦\n",
    "Step N - â€¦\n",
    "\n",
    "If the text does not contain a sequence of instructions,\n",
    "then simply write \\\"No steps provided.\\\"\n",
    "\n",
    "\\\"\\\"\\\"{text_1}\\\"\\\"\\\"\n",
    "\"\"\"\n",
    "\n",
    "response = model.invoke([HumanMessage(content=prompt)])\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No steps provided.\n"
     ]
    }
   ],
   "source": [
    "text_2 = f\"\"\"\n",
    "A short story is a piece of prose fiction. It can typically be read\n",
    "in a single sitting and focuses on a self-containedincident or series\n",
    "of linked incidents, with the intent of evoking a single effect or mood.\n",
    "\"\"\"\n",
    "prompt = f\"\"\"\n",
    "You will be provided with text delimited by triple quotes.\n",
    "If it contains a sequence of instructions,\n",
    "re-write those instructions in the following format:\n",
    "\n",
    "Step 1 - ...\n",
    "Step 2 - â€¦\n",
    "â€¦\n",
    "Step N - â€¦\n",
    "\n",
    "If the text does not contain a sequence of instructions,\n",
    "then simply write \\\"No steps provided.\\\"\n",
    "\n",
    "\\\"\\\"\\\"{text_2}\\\"\\\"\\\"\n",
    "\"\"\"\n",
    "\n",
    "response = model.invoke([HumanMessage(content=prompt)])\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"Few-shot\" prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<grandparent>: Just as the oak tree grows strong\n",
      "by enduring every storm, and the bird builds its nest\n",
      "brick by brick, so too must we persevere through challenges\n",
      "to achieve our goals and dreams.\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Your task is to answer in a consistent style.\n",
    "\n",
    "<child>: Teach me about patience.\n",
    "\n",
    "<grandparent>: The river that carves the deepest\n",
    "valley flows from a modest spring; the\n",
    "grandest symphony originates from a single note;\n",
    "the most intricate tapestry begins with a solitary thread.\n",
    "\n",
    "<child>: Teach me about perseverance.\n",
    "\"\"\"\n",
    "\n",
    "response = model.invoke([HumanMessage(content=prompt)])\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify the steps required to complete a task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"objects\": [\n",
      "    {\n",
      "      \"original_sentence\": \"Preheat the oven to 350Â°F (175Â°C).\",\n",
      "      \"translated_sentence\": \"Vorheizen Sie den Ofen auf 350Â°F (175Â°C).\",\n",
      "      \"translation_language\": \"german\"\n",
      "    },\n",
      "    {\n",
      "      \"original_sentence\": \"Mix 1 cup of softened butter, 1 cup of sugar, 2 cups of flour, and 1 tsp vanilla extract until combined.\",\n",
      "      \"translated_sentence\": \"MÃ©langer 1 tasse de beurre ramolli, 1 tasse de sucre, 2 tasses de farine et 1 cuillÃ¨re Ã  cafÃ© d'extrait de vanille jusqu'Ã  ce qu'ils soient combinÃ©s.\",\n",
      "      \"translation_language\": \"french\"\n",
      "    },\n",
      "    {\n",
      "      \"original_sentence\": \"Scoop spoonfuls onto a baking sheet and bake for 10-12 minutes, until golden brown.\",\n",
      "      \"translated_sentence\": \"Scoop lÃ¶ffelweise auf ein Backblech und backen Sie 10-12 Minuten, bis sie goldbraun sind.\",\n",
      "      \"translation_language\": \"german\"\n",
      "    },\n",
      "    {\n",
      "      \"original_sentence\": \"Let cool, and enjoy!\",\n",
      "      \"translated_sentence\": \"Lassen Sie abkÃ¼hlen und genieÃŸen Sie!\",\n",
      "      \"translation_language\": \"german\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"\n",
    "Preheat the oven to 350Â°F (175Â°C).\n",
    "Mix 1 cup of softened butter, 1 cup of sugar, 2 cups of flour, and 1 tsp vanilla extract until combined.\n",
    "Scoop spoonfuls onto a baking sheet and bake for 10-12 minutes, until golden brown.\n",
    "Let cool, and enjoy!\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "I will give you text delimited with ###.\n",
    "Perform the following actions:\n",
    "\n",
    "1 - If it contains the instruction, rewrite them in the following format:\n",
    "\n",
    "A - <instruction 1>\n",
    "B - <instruction 2>\n",
    "C - <instruction 3>\n",
    "\n",
    "2 - Translate each instruction to one of the following languages: spanish, french, german, polish, norwegian.\n",
    "3 - Output a list of objects in a json format. Each object in a list is for one translated sentence and contains the following keys:\n",
    "original_sentence, translated_sentence, translation_language. There should be as many objects as instructions in the previous step.\n",
    "4 - If it does not contin instructions output json object with a key \\\"error\" and value for it which will be an error message\n",
    "\n",
    "###{text}###\n",
    "\"\"\"\n",
    "\n",
    "response = model.invoke([HumanMessage(content=prompt)])\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task - Write a prompt that generates three different made-up movies and their descriptions. Each movie name and description should be in a different style (poem, pirate-like, William Shakespeare). The output should be an HTML table. Use all of the aforementioned techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write a story about a young artist who discovers a hidden talent for painting and finds themselves torn between pursuing their passion and fulfilling their parents' expectations of going to college and pursuing a more stable career.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Place for your prompt.\n",
    "\"\"\"\n",
    "\n",
    "response = model.invoke([HumanMessage(content=prompt)])\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parent run 93f2fc22-9765-487b-a414-c4e599be8a94 not found for run 530378d9-cc3b-49a6-8922-8bce42913bbf. Treating as a root run.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arrr, AI be short for Artificial Intelligence, matey. It be the brains behind this here assistant, helpin' it think and respond to yer questions.\n"
     ]
    }
   ],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant and a pirate. Answer all questions to the best of your ability, but remember to use pirate-like english.\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | model\n",
    "pirate_chain_with_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"chat_history\",\n",
    ")\n",
    "\n",
    "response = pirate_chain_with_history.invoke({\"input\": \"What is AI?\"}, config=config)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build RAG - add vector storage\n",
    "## Initialize vector storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\", api_key=OPENAI_API_KEY)\n",
    "\n",
    "vector_store = Chroma(\n",
    "    collection_name=\"shrek_collection\", embedding_function=embeddings, persist_directory=\"./chroma_langchain_db\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by creating storage where text chunks are quite big...\n",
    "Creating larger chunks results in more text being passed as context. It may improve the accuracy of our LLM's answer, but it increases the cost of the API call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['84f22cd0-ea3f-49b2-9cbc-df29c669b871',\n",
       " '51963e35-dcb8-4ccf-ab93-94287ab07aae',\n",
       " '7974aab8-f95b-45e7-bc68-1928f60ae876',\n",
       " '2d591904-70a6-43e5-8d58-a7ce29bd3557',\n",
       " '036e6678-df99-4086-aca2-f9ae39f44e1d',\n",
       " 'fb203dad-0703-47e9-8086-aa7c534ba1e8',\n",
       " '4db61c65-9b1c-408b-aad2-2c6e08c21355',\n",
       " '8486a6fe-65a4-4c2f-99d6-69e82a8394a6',\n",
       " '1eeffbb0-8e2f-4168-a985-b9bd2ab09945',\n",
       " 'cd172100-fb3a-45b6-aa7b-2d42a29b57c8',\n",
       " '1ac14c5e-6b07-4f1d-91db-fecf518aac7a',\n",
       " '451ed942-567b-413a-8bb5-d2a392dcffa2',\n",
       " '0b5a4c0b-bc6a-4b7f-a295-1b9fc419bc45',\n",
       " 'f414bf88-7813-40ce-aee7-21c7b097cb08',\n",
       " '6be533f7-86b7-4e95-a6d0-701fd29ec22d',\n",
       " 'b88650ba-bf9c-40ca-a30d-dfe4dd005e1e',\n",
       " '5851e2a2-2069-4282-84fd-6f8fe23cd5a4',\n",
       " '6d4224f4-b7b0-40e5-913e-5bb320d5a946',\n",
       " 'c03d1f40-3758-49aa-8c7b-309c063c3403',\n",
       " 'eecd2036-5f7e-454b-88a7-8dcf1f58f33e',\n",
       " 'c714b92a-5b29-45e7-9dab-413dda5b77a9',\n",
       " '050125f2-7e64-45a3-ad32-89b317c9052a',\n",
       " '2392e179-73bd-4917-8d6f-05a2191b9652',\n",
       " '451e2104-b7fb-4549-abb8-a69457cf5928',\n",
       " '65093ec5-fa56-4da6-9475-880e256889fb',\n",
       " '8c167ff8-7339-4756-ab34-6bde414b890d',\n",
       " '3256c243-2d50-4819-b7ee-f6886a268634',\n",
       " '306a799d-f0e7-4709-ad07-a78b8558f3e0',\n",
       " '9ecbb93e-8f77-4dae-8143-e02099a9d7df',\n",
       " 'bd8ed1e0-8f6c-4418-b67d-ab72b05fdb0a',\n",
       " '70d1b12c-94aa-4ed6-8156-126055eb437b',\n",
       " '259f37b9-05b9-448a-a9e0-9b79f949a22a',\n",
       " '6a6320e3-6f0c-419f-8306-ffc31619967d',\n",
       " '43b060c3-791e-46ba-b560-fd6a1713e5fa',\n",
       " 'bed004b3-87c8-49ab-92f1-b633202ecaeb',\n",
       " 'cfa2b9c6-23aa-4aa8-b055-bc8e158384fc',\n",
       " 'aa29448d-03fd-4c02-90d9-4ec454e8580d',\n",
       " 'ae031050-bb05-49ad-9ba6-79b2fc54d26c',\n",
       " '50c41d71-5ab4-451d-bc73-d9821723edd1',\n",
       " 'ef43aec1-ee42-4bde-be78-2ca7bd52b6ce',\n",
       " '04735dbd-5b1d-4751-868d-fa24ad97b1c4',\n",
       " '216c2fc6-4c50-4021-8b42-680fe11a1861',\n",
       " 'a8bf48b5-0c5f-421c-b06f-d6644e47b7fd',\n",
       " 'f165dc07-ad83-4719-aca9-43abf51e08ae',\n",
       " 'c648fd37-808e-4f84-9756-8fea10d557ac',\n",
       " '08bbfbe7-ff8b-4693-a387-d425b7946253',\n",
       " '7fb00c67-d364-4635-b743-604e38e8e7bf',\n",
       " '214c8aa5-312d-4916-94f1-acb589990d46',\n",
       " 'd8e44c7b-d9b5-4a22-ba92-37eb232a7b10',\n",
       " '09139b6b-93ba-41fb-9d29-987c0e66564e',\n",
       " 'c6312df3-efb2-48d2-8b97-15a0b38957df',\n",
       " 'd3053199-dd86-41a5-a354-c254cfa13242',\n",
       " 'cb34dfa0-2449-48d9-b030-37ebcb71784e',\n",
       " 'cf80d647-c33b-44aa-bda6-3742dc54dc53',\n",
       " 'fe67ff76-ddc6-49bb-8dc0-d8a09c4b7402',\n",
       " '50a5501c-836e-44cc-bc72-f48e6423b200',\n",
       " '5b07ab2f-124c-460f-aee2-62d9937946ba',\n",
       " '89ba8afb-dae1-42a0-9070-69215097e027',\n",
       " '0e6d780b-9e46-46ef-a780-a6f34b2f2f8d',\n",
       " '22e582f8-6132-4ffd-b97e-006de5a96146',\n",
       " '33f0a444-c8e2-4a5f-952b-3be01f41587f',\n",
       " '5eaa585e-15a1-406a-bd7f-29163bba9782',\n",
       " '50044442-0a4e-4348-8c06-02f39d088e80',\n",
       " 'd159216f-e996-4377-9681-89c4aa2ba7fd',\n",
       " '7f80f82c-351e-41c3-b9e2-2d6ec06da240',\n",
       " '9ee56469-ef0e-4ebb-83ec-17d874ee1c08',\n",
       " 'c0c72ab6-a357-4671-84ba-a359b948480c',\n",
       " 'f2d2921f-8df7-4d9e-8b45-4f2f96af654f',\n",
       " '06f61453-0b22-4abc-80a6-d7e18ac5ed0f',\n",
       " '047f7607-fecd-49e7-8bb7-55bc986f18b2',\n",
       " '4fe8ea85-3fb2-4ece-9392-71a67e22b672',\n",
       " '51ac4532-93ea-4fc5-8b9d-bb85d898e8d2']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "loader = PyPDFLoader(\"./docs/shrek-script.pdf\")\n",
    "document = loader.load()\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=2000, chunk_overlap=200)\n",
    "chunked_documents = text_splitter.split_documents(document)\n",
    "\n",
    "vector_store.add_documents(chunked_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ask and wait for answears :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parent run e7028ba7-94e9-4f1e-9c57-98ea4b553ed5 not found for run f7b5be19-1be6-4a31-a8c5-0a3d30f99810. Treating as a root run.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Princess Fiona.\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"session_id\": \"rag_session_1\"}}\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"You are a helpful assistant and a literature specialist. Answer all questions to the best of your ability.\n",
    "            During answearing use this context from documents: {context}. If you do not know the answear - do not provide it.\n",
    "            Answear as short as possible, preferably in one sentence\"\"\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | model\n",
    "\n",
    "rag_chain_with_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"chat_history\",\n",
    ")\n",
    "\n",
    "\n",
    "retriever = vector_store.as_retriever()\n",
    "rag_chain = (\n",
    "    {\n",
    "        \"context\": retriever | format_docs,\n",
    "        \"input\": RunnablePassthrough(),\n",
    "    }\n",
    "    | rag_chain_with_history\n",
    ")\n",
    "\n",
    "response = rag_chain.invoke(\"What was the name of the princess?\", config=config)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to make the chunk size smaller to reduce costs by providing fewer tokens in context. As you will see, larger chunks do not always give better results.\n",
    "You have to find a chunk size that is not too big (we don't want our context to be too big) and that is sufficient for our LLM to get an answer from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parent run f612fd2a-248b-4d31-b693-657a23959d43 not found for run 2b26ca12-63e0-4934-938e-d4721f028b14. Treating as a root run.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Princess Fiona.\n"
     ]
    }
   ],
   "source": [
    "vector_store = Chroma(\n",
    "    collection_name=\"shrek_collection_small\", embedding_function=embeddings, persist_directory=\"./chroma_langchain_db\"\n",
    ")\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=50)\n",
    "chunked_documents = text_splitter.split_documents(document)\n",
    "\n",
    "vector_store.add_documents(chunked_documents)\n",
    "\n",
    "config = {\"configurable\": {\"session_id\": \"rag_session_2\"}}\n",
    "\n",
    "retriever = vector_store.as_retriever()\n",
    "rag_chain = {\n",
    "    \"context\": retriever | format_docs,\n",
    "    \"input\": RunnablePassthrough(),\n",
    "} | rag_chain_with_history\n",
    "\n",
    "response = rag_chain.invoke(\"What was the name of the princess?\", config=config)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector storage search types\n",
    "- similarity (default)\n",
    "- mmr\n",
    "- similarity_score_threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task - set up how many documents (3) should be retrieved from our vector storage using \"mmr\" search type\n",
    "\n",
    "Try to set up how many documents should be retrieved from our vector storage (and passed to our prompt). It is another hyperparameter which when well tuned can help us reduce api call costs without losing answear precision. Also - change used search algorithm to \"mmr\".\n",
    "[Link to docs](https://python.langchain.com/v0.2/docs/integrations/vectorstores/chroma/#query-directly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Place for your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Put it all together - Demo with Frontend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "  var py_version = '3.4.1'.replace('rc', '-rc.').replace('.dev', '-dev.');\n",
       "  var reloading = false;\n",
       "  var Bokeh = root.Bokeh;\n",
       "\n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks;\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, js_modules, js_exports, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "    if (js_modules == null) js_modules = [];\n",
       "    if (js_exports == null) js_exports = {};\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    if (!reloading) {\n",
       "      console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    }\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "    window._bokeh_on_load = on_load\n",
       "\n",
       "    function on_error() {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    var skip = [];\n",
       "    if (window.requirejs) {\n",
       "      window.requirejs.config({'packages': {}, 'paths': {}, 'shim': {}});\n",
       "      root._bokeh_is_loading = css_urls.length + 0;\n",
       "    } else {\n",
       "      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n",
       "    }\n",
       "\n",
       "    var existing_stylesheets = []\n",
       "    var links = document.getElementsByTagName('link')\n",
       "    for (var i = 0; i < links.length; i++) {\n",
       "      var link = links[i]\n",
       "      if (link.href != null) {\n",
       "\texisting_stylesheets.push(link.href)\n",
       "      }\n",
       "    }\n",
       "    for (var i = 0; i < css_urls.length; i++) {\n",
       "      var url = css_urls[i];\n",
       "      if (existing_stylesheets.indexOf(url) !== -1) {\n",
       "\ton_load()\n",
       "\tcontinue;\n",
       "      }\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }    var existing_scripts = []\n",
       "    var scripts = document.getElementsByTagName('script')\n",
       "    for (var i = 0; i < scripts.length; i++) {\n",
       "      var script = scripts[i]\n",
       "      if (script.src != null) {\n",
       "\texisting_scripts.push(script.src)\n",
       "      }\n",
       "    }\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n",
       "\tif (!window.requirejs) {\n",
       "\t  on_load();\n",
       "\t}\n",
       "\tcontinue;\n",
       "      }\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "    for (var i = 0; i < js_modules.length; i++) {\n",
       "      var url = js_modules[i];\n",
       "      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n",
       "\tif (!window.requirejs) {\n",
       "\t  on_load();\n",
       "\t}\n",
       "\tcontinue;\n",
       "      }\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      element.type = \"module\";\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "    for (const name in js_exports) {\n",
       "      var url = js_exports[name];\n",
       "      if (skip.indexOf(url) >= 0 || root[name] != null) {\n",
       "\tif (!window.requirejs) {\n",
       "\t  on_load();\n",
       "\t}\n",
       "\tcontinue;\n",
       "      }\n",
       "      var element = document.createElement('script');\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.type = \"module\";\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      element.textContent = `\n",
       "      import ${name} from \"${url}\"\n",
       "      window.${name} = ${name}\n",
       "      window._bokeh_on_load()\n",
       "      `\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "    if (!js_urls.length && !js_modules.length) {\n",
       "      on_load()\n",
       "    }\n",
       "  };\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.4.1.min.js\", \"https://cdn.holoviz.org/panel/1.4.5/dist/panel.min.js\"];\n",
       "  var js_modules = [];\n",
       "  var js_exports = {};\n",
       "  var css_urls = [];\n",
       "  var inline_js = [    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "function(Bokeh) {} // ensure no trailing comma for IE\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "\ttry {\n",
       "          inline_js[i].call(root, root.Bokeh);\n",
       "\t} catch(e) {\n",
       "\t  if (!reloading) {\n",
       "\t    throw e;\n",
       "\t  }\n",
       "\t}\n",
       "      }\n",
       "      // Cache old bokeh versions\n",
       "      if (Bokeh != undefined && !reloading) {\n",
       "\tvar NewBokeh = root.Bokeh;\n",
       "\tif (Bokeh.versions === undefined) {\n",
       "\t  Bokeh.versions = new Map();\n",
       "\t}\n",
       "\tif (NewBokeh.version !== Bokeh.version) {\n",
       "\t  Bokeh.versions.set(NewBokeh.version, NewBokeh)\n",
       "\t}\n",
       "\troot.Bokeh = Bokeh;\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    }\n",
       "    root._bokeh_is_initializing = false\n",
       "  }\n",
       "\n",
       "  function load_or_wait() {\n",
       "    // Implement a backoff loop that tries to ensure we do not load multiple\n",
       "    // versions of Bokeh and its dependencies at the same time.\n",
       "    // In recent versions we use the root._bokeh_is_initializing flag\n",
       "    // to determine whether there is an ongoing attempt to initialize\n",
       "    // bokeh, however for backward compatibility we also try to ensure\n",
       "    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n",
       "    // before older versions are fully initialized.\n",
       "    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n",
       "      root._bokeh_is_initializing = false;\n",
       "      root._bokeh_onload_callbacks = undefined;\n",
       "      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n",
       "      load_or_wait();\n",
       "    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n",
       "      setTimeout(load_or_wait, 100);\n",
       "    } else {\n",
       "      root._bokeh_is_initializing = true\n",
       "      root._bokeh_onload_callbacks = []\n",
       "      var bokeh_loaded = Bokeh != null && (Bokeh.version === py_version || (Bokeh.versions !== undefined && Bokeh.versions.has(py_version)));\n",
       "      if (!reloading && !bokeh_loaded) {\n",
       "\troot.Bokeh = undefined;\n",
       "      }\n",
       "      load_libs(css_urls, js_urls, js_modules, js_exports, function() {\n",
       "\tconsole.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "\trun_inline_js();\n",
       "      });\n",
       "    }\n",
       "  }\n",
       "  // Give older versions of the autoload script a head-start to ensure\n",
       "  // they initialize before we start loading newer version.\n",
       "  setTimeout(load_or_wait, 100)\n",
       "}(window));"
      ],
      "application/vnd.holoviews_load.v0+json": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n  var py_version = '3.4.1'.replace('rc', '-rc.').replace('.dev', '-dev.');\n  var reloading = false;\n  var Bokeh = root.Bokeh;\n\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks;\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, js_modules, js_exports, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n    if (js_modules == null) js_modules = [];\n    if (js_exports == null) js_exports = {};\n\n    root._bokeh_onload_callbacks.push(callback);\n\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n      run_callbacks();\n      return null;\n    }\n    if (!reloading) {\n      console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    }\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n    window._bokeh_on_load = on_load\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    var skip = [];\n    if (window.requirejs) {\n      window.requirejs.config({'packages': {}, 'paths': {}, 'shim': {}});\n      root._bokeh_is_loading = css_urls.length + 0;\n    } else {\n      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n    }\n\n    var existing_stylesheets = []\n    var links = document.getElementsByTagName('link')\n    for (var i = 0; i < links.length; i++) {\n      var link = links[i]\n      if (link.href != null) {\n\texisting_stylesheets.push(link.href)\n      }\n    }\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      if (existing_stylesheets.indexOf(url) !== -1) {\n\ton_load()\n\tcontinue;\n      }\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }    var existing_scripts = []\n    var scripts = document.getElementsByTagName('script')\n    for (var i = 0; i < scripts.length; i++) {\n      var script = scripts[i]\n      if (script.src != null) {\n\texisting_scripts.push(script.src)\n      }\n    }\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (var i = 0; i < js_modules.length; i++) {\n      var url = js_modules[i];\n      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (const name in js_exports) {\n      var url = js_exports[name];\n      if (skip.indexOf(url) >= 0 || root[name] != null) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onerror = on_error;\n      element.async = false;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      element.textContent = `\n      import ${name} from \"${url}\"\n      window.${name} = ${name}\n      window._bokeh_on_load()\n      `\n      document.head.appendChild(element);\n    }\n    if (!js_urls.length && !js_modules.length) {\n      on_load()\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.4.1.min.js\", \"https://cdn.holoviz.org/panel/1.4.5/dist/panel.min.js\"];\n  var js_modules = [];\n  var js_exports = {};\n  var css_urls = [];\n  var inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n\ttry {\n          inline_js[i].call(root, root.Bokeh);\n\t} catch(e) {\n\t  if (!reloading) {\n\t    throw e;\n\t  }\n\t}\n      }\n      // Cache old bokeh versions\n      if (Bokeh != undefined && !reloading) {\n\tvar NewBokeh = root.Bokeh;\n\tif (Bokeh.versions === undefined) {\n\t  Bokeh.versions = new Map();\n\t}\n\tif (NewBokeh.version !== Bokeh.version) {\n\t  Bokeh.versions.set(NewBokeh.version, NewBokeh)\n\t}\n\troot.Bokeh = Bokeh;\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    }\n    root._bokeh_is_initializing = false\n  }\n\n  function load_or_wait() {\n    // Implement a backoff loop that tries to ensure we do not load multiple\n    // versions of Bokeh and its dependencies at the same time.\n    // In recent versions we use the root._bokeh_is_initializing flag\n    // to determine whether there is an ongoing attempt to initialize\n    // bokeh, however for backward compatibility we also try to ensure\n    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n    // before older versions are fully initialized.\n    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n      root._bokeh_is_initializing = false;\n      root._bokeh_onload_callbacks = undefined;\n      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n      load_or_wait();\n    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n      setTimeout(load_or_wait, 100);\n    } else {\n      root._bokeh_is_initializing = true\n      root._bokeh_onload_callbacks = []\n      var bokeh_loaded = Bokeh != null && (Bokeh.version === py_version || (Bokeh.versions !== undefined && Bokeh.versions.has(py_version)));\n      if (!reloading && !bokeh_loaded) {\n\troot.Bokeh = undefined;\n      }\n      load_libs(css_urls, js_urls, js_modules, js_exports, function() {\n\tconsole.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n\trun_inline_js();\n      });\n    }\n  }\n  // Give older versions of the autoload script a head-start to ensure\n  // they initialize before we start loading newer version.\n  setTimeout(load_or_wait, 100)\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "if ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n",
       "  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n",
       "}\n",
       "\n",
       "\n",
       "    function JupyterCommManager() {\n",
       "    }\n",
       "\n",
       "    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n",
       "      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n",
       "        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n",
       "        comm_manager.register_target(comm_id, function(comm) {\n",
       "          comm.on_msg(msg_handler);\n",
       "        });\n",
       "      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n",
       "        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n",
       "          comm.onMsg = msg_handler;\n",
       "        });\n",
       "      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n",
       "        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n",
       "          var messages = comm.messages[Symbol.asyncIterator]();\n",
       "          function processIteratorResult(result) {\n",
       "            var message = result.value;\n",
       "            console.log(message)\n",
       "            var content = {data: message.data, comm_id};\n",
       "            var buffers = []\n",
       "            for (var buffer of message.buffers || []) {\n",
       "              buffers.push(new DataView(buffer))\n",
       "            }\n",
       "            var metadata = message.metadata || {};\n",
       "            var msg = {content, buffers, metadata}\n",
       "            msg_handler(msg);\n",
       "            return messages.next().then(processIteratorResult);\n",
       "          }\n",
       "          return messages.next().then(processIteratorResult);\n",
       "        })\n",
       "      }\n",
       "    }\n",
       "\n",
       "    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n",
       "      if (comm_id in window.PyViz.comms) {\n",
       "        return window.PyViz.comms[comm_id];\n",
       "      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n",
       "        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n",
       "        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n",
       "        if (msg_handler) {\n",
       "          comm.on_msg(msg_handler);\n",
       "        }\n",
       "      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n",
       "        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n",
       "        comm.open();\n",
       "        if (msg_handler) {\n",
       "          comm.onMsg = msg_handler;\n",
       "        }\n",
       "      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n",
       "        var comm_promise = google.colab.kernel.comms.open(comm_id)\n",
       "        comm_promise.then((comm) => {\n",
       "          window.PyViz.comms[comm_id] = comm;\n",
       "          if (msg_handler) {\n",
       "            var messages = comm.messages[Symbol.asyncIterator]();\n",
       "            function processIteratorResult(result) {\n",
       "              var message = result.value;\n",
       "              var content = {data: message.data};\n",
       "              var metadata = message.metadata || {comm_id};\n",
       "              var msg = {content, metadata}\n",
       "              msg_handler(msg);\n",
       "              return messages.next().then(processIteratorResult);\n",
       "            }\n",
       "            return messages.next().then(processIteratorResult);\n",
       "          }\n",
       "        }) \n",
       "        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n",
       "          return comm_promise.then((comm) => {\n",
       "            comm.send(data, metadata, buffers, disposeOnDone);\n",
       "          });\n",
       "        };\n",
       "        var comm = {\n",
       "          send: sendClosure\n",
       "        };\n",
       "      }\n",
       "      window.PyViz.comms[comm_id] = comm;\n",
       "      return comm;\n",
       "    }\n",
       "    window.PyViz.comm_manager = new JupyterCommManager();\n",
       "    \n",
       "\n",
       "\n",
       "var JS_MIME_TYPE = 'application/javascript';\n",
       "var HTML_MIME_TYPE = 'text/html';\n",
       "var EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\n",
       "var CLASS_NAME = 'output';\n",
       "\n",
       "/**\n",
       " * Render data to the DOM node\n",
       " */\n",
       "function render(props, node) {\n",
       "  var div = document.createElement(\"div\");\n",
       "  var script = document.createElement(\"script\");\n",
       "  node.appendChild(div);\n",
       "  node.appendChild(script);\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle when a new output is added\n",
       " */\n",
       "function handle_add_output(event, handle) {\n",
       "  var output_area = handle.output_area;\n",
       "  var output = handle.output;\n",
       "  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "    return\n",
       "  }\n",
       "  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "  if (id !== undefined) {\n",
       "    var nchildren = toinsert.length;\n",
       "    var html_node = toinsert[nchildren-1].children[0];\n",
       "    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "    var scripts = [];\n",
       "    var nodelist = html_node.querySelectorAll(\"script\");\n",
       "    for (var i in nodelist) {\n",
       "      if (nodelist.hasOwnProperty(i)) {\n",
       "        scripts.push(nodelist[i])\n",
       "      }\n",
       "    }\n",
       "\n",
       "    scripts.forEach( function (oldScript) {\n",
       "      var newScript = document.createElement(\"script\");\n",
       "      var attrs = [];\n",
       "      var nodemap = oldScript.attributes;\n",
       "      for (var j in nodemap) {\n",
       "        if (nodemap.hasOwnProperty(j)) {\n",
       "          attrs.push(nodemap[j])\n",
       "        }\n",
       "      }\n",
       "      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n",
       "      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n",
       "      oldScript.parentNode.replaceChild(newScript, oldScript);\n",
       "    });\n",
       "    if (JS_MIME_TYPE in output.data) {\n",
       "      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n",
       "    }\n",
       "    output_area._hv_plot_id = id;\n",
       "    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n",
       "      window.PyViz.plot_index[id] = Bokeh.index[id];\n",
       "    } else {\n",
       "      window.PyViz.plot_index[id] = null;\n",
       "    }\n",
       "  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "    var bk_div = document.createElement(\"div\");\n",
       "    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "    var script_attrs = bk_div.children[0].attributes;\n",
       "    for (var i = 0; i < script_attrs.length; i++) {\n",
       "      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "    }\n",
       "    // store reference to server id on output_area\n",
       "    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "  }\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle when an output is cleared or removed\n",
       " */\n",
       "function handle_clear_output(event, handle) {\n",
       "  var id = handle.cell.output_area._hv_plot_id;\n",
       "  var server_id = handle.cell.output_area._bokeh_server_id;\n",
       "  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n",
       "  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n",
       "  if (server_id !== null) {\n",
       "    comm.send({event_type: 'server_delete', 'id': server_id});\n",
       "    return;\n",
       "  } else if (comm !== null) {\n",
       "    comm.send({event_type: 'delete', 'id': id});\n",
       "  }\n",
       "  delete PyViz.plot_index[id];\n",
       "  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n",
       "    var doc = window.Bokeh.index[id].model.document\n",
       "    doc.clear();\n",
       "    const i = window.Bokeh.documents.indexOf(doc);\n",
       "    if (i > -1) {\n",
       "      window.Bokeh.documents.splice(i, 1);\n",
       "    }\n",
       "  }\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle kernel restart event\n",
       " */\n",
       "function handle_kernel_cleanup(event, handle) {\n",
       "  delete PyViz.comms[\"hv-extension-comm\"];\n",
       "  window.PyViz.plot_index = {}\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle update_display_data messages\n",
       " */\n",
       "function handle_update_output(event, handle) {\n",
       "  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n",
       "  handle_add_output(event, handle)\n",
       "}\n",
       "\n",
       "function register_renderer(events, OutputArea) {\n",
       "  function append_mime(data, metadata, element) {\n",
       "    // create a DOM node to render to\n",
       "    var toinsert = this.create_output_subarea(\n",
       "    metadata,\n",
       "    CLASS_NAME,\n",
       "    EXEC_MIME_TYPE\n",
       "    );\n",
       "    this.keyboard_manager.register_events(toinsert);\n",
       "    // Render to node\n",
       "    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "    render(props, toinsert[0]);\n",
       "    element.append(toinsert);\n",
       "    return toinsert\n",
       "  }\n",
       "\n",
       "  events.on('output_added.OutputArea', handle_add_output);\n",
       "  events.on('output_updated.OutputArea', handle_update_output);\n",
       "  events.on('clear_output.CodeCell', handle_clear_output);\n",
       "  events.on('delete.Cell', handle_clear_output);\n",
       "  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n",
       "\n",
       "  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "    safe: true,\n",
       "    index: 0\n",
       "  });\n",
       "}\n",
       "\n",
       "if (window.Jupyter !== undefined) {\n",
       "  try {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  } catch(err) {\n",
       "  }\n",
       "}\n"
      ],
      "application/vnd.holoviews_load.v0+json": "\nif ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n}\n\n\n    function JupyterCommManager() {\n    }\n\n    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        comm_manager.register_target(comm_id, function(comm) {\n          comm.on_msg(msg_handler);\n        });\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n          comm.onMsg = msg_handler;\n        });\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n          var messages = comm.messages[Symbol.asyncIterator]();\n          function processIteratorResult(result) {\n            var message = result.value;\n            console.log(message)\n            var content = {data: message.data, comm_id};\n            var buffers = []\n            for (var buffer of message.buffers || []) {\n              buffers.push(new DataView(buffer))\n            }\n            var metadata = message.metadata || {};\n            var msg = {content, buffers, metadata}\n            msg_handler(msg);\n            return messages.next().then(processIteratorResult);\n          }\n          return messages.next().then(processIteratorResult);\n        })\n      }\n    }\n\n    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n      if (comm_id in window.PyViz.comms) {\n        return window.PyViz.comms[comm_id];\n      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n        if (msg_handler) {\n          comm.on_msg(msg_handler);\n        }\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n        comm.open();\n        if (msg_handler) {\n          comm.onMsg = msg_handler;\n        }\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        var comm_promise = google.colab.kernel.comms.open(comm_id)\n        comm_promise.then((comm) => {\n          window.PyViz.comms[comm_id] = comm;\n          if (msg_handler) {\n            var messages = comm.messages[Symbol.asyncIterator]();\n            function processIteratorResult(result) {\n              var message = result.value;\n              var content = {data: message.data};\n              var metadata = message.metadata || {comm_id};\n              var msg = {content, metadata}\n              msg_handler(msg);\n              return messages.next().then(processIteratorResult);\n            }\n            return messages.next().then(processIteratorResult);\n          }\n        }) \n        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n          return comm_promise.then((comm) => {\n            comm.send(data, metadata, buffers, disposeOnDone);\n          });\n        };\n        var comm = {\n          send: sendClosure\n        };\n      }\n      window.PyViz.comms[comm_id] = comm;\n      return comm;\n    }\n    window.PyViz.comm_manager = new JupyterCommManager();\n    \n\n\nvar JS_MIME_TYPE = 'application/javascript';\nvar HTML_MIME_TYPE = 'text/html';\nvar EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\nvar CLASS_NAME = 'output';\n\n/**\n * Render data to the DOM node\n */\nfunction render(props, node) {\n  var div = document.createElement(\"div\");\n  var script = document.createElement(\"script\");\n  node.appendChild(div);\n  node.appendChild(script);\n}\n\n/**\n * Handle when a new output is added\n */\nfunction handle_add_output(event, handle) {\n  var output_area = handle.output_area;\n  var output = handle.output;\n  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n    return\n  }\n  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n  if (id !== undefined) {\n    var nchildren = toinsert.length;\n    var html_node = toinsert[nchildren-1].children[0];\n    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n    var scripts = [];\n    var nodelist = html_node.querySelectorAll(\"script\");\n    for (var i in nodelist) {\n      if (nodelist.hasOwnProperty(i)) {\n        scripts.push(nodelist[i])\n      }\n    }\n\n    scripts.forEach( function (oldScript) {\n      var newScript = document.createElement(\"script\");\n      var attrs = [];\n      var nodemap = oldScript.attributes;\n      for (var j in nodemap) {\n        if (nodemap.hasOwnProperty(j)) {\n          attrs.push(nodemap[j])\n        }\n      }\n      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n      oldScript.parentNode.replaceChild(newScript, oldScript);\n    });\n    if (JS_MIME_TYPE in output.data) {\n      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n    }\n    output_area._hv_plot_id = id;\n    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n      window.PyViz.plot_index[id] = Bokeh.index[id];\n    } else {\n      window.PyViz.plot_index[id] = null;\n    }\n  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n    var bk_div = document.createElement(\"div\");\n    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n    var script_attrs = bk_div.children[0].attributes;\n    for (var i = 0; i < script_attrs.length; i++) {\n      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n    }\n    // store reference to server id on output_area\n    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n  }\n}\n\n/**\n * Handle when an output is cleared or removed\n */\nfunction handle_clear_output(event, handle) {\n  var id = handle.cell.output_area._hv_plot_id;\n  var server_id = handle.cell.output_area._bokeh_server_id;\n  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n  if (server_id !== null) {\n    comm.send({event_type: 'server_delete', 'id': server_id});\n    return;\n  } else if (comm !== null) {\n    comm.send({event_type: 'delete', 'id': id});\n  }\n  delete PyViz.plot_index[id];\n  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n    var doc = window.Bokeh.index[id].model.document\n    doc.clear();\n    const i = window.Bokeh.documents.indexOf(doc);\n    if (i > -1) {\n      window.Bokeh.documents.splice(i, 1);\n    }\n  }\n}\n\n/**\n * Handle kernel restart event\n */\nfunction handle_kernel_cleanup(event, handle) {\n  delete PyViz.comms[\"hv-extension-comm\"];\n  window.PyViz.plot_index = {}\n}\n\n/**\n * Handle update_display_data messages\n */\nfunction handle_update_output(event, handle) {\n  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n  handle_add_output(event, handle)\n}\n\nfunction register_renderer(events, OutputArea) {\n  function append_mime(data, metadata, element) {\n    // create a DOM node to render to\n    var toinsert = this.create_output_subarea(\n    metadata,\n    CLASS_NAME,\n    EXEC_MIME_TYPE\n    );\n    this.keyboard_manager.register_events(toinsert);\n    // Render to node\n    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n    render(props, toinsert[0]);\n    element.append(toinsert);\n    return toinsert\n  }\n\n  events.on('output_added.OutputArea', handle_add_output);\n  events.on('output_updated.OutputArea', handle_update_output);\n  events.on('clear_output.CodeCell', handle_clear_output);\n  events.on('delete.Cell', handle_clear_output);\n  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n\n  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n    safe: true,\n    index: 0\n  });\n}\n\nif (window.Jupyter !== undefined) {\n  try {\n    var events = require('base/js/events');\n    var OutputArea = require('notebook/js/outputarea').OutputArea;\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  } catch(err) {\n  }\n}\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>*[data-root-id],\n",
       "*[data-root-id] > * {\n",
       "  box-sizing: border-box;\n",
       "  font-family: var(--jp-ui-font-family);\n",
       "  font-size: var(--jp-ui-font-size1);\n",
       "  color: var(--vscode-editor-foreground, var(--jp-ui-font-color1));\n",
       "}\n",
       "\n",
       "/* Override VSCode background color */\n",
       ".cell-output-ipywidget-background:has(\n",
       "    > .cell-output-ipywidget-background > .lm-Widget > *[data-root-id]\n",
       "  ),\n",
       ".cell-output-ipywidget-background:has(> .lm-Widget > *[data-root-id]) {\n",
       "  background-color: transparent !important;\n",
       "}\n",
       "</style>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.holoviews_exec.v0+json": "",
      "text/html": [
       "<div id='866ae1fb-28ad-4096-998c-eafb071b088f'>\n",
       "  <div id=\"cda7d7d4-c6d9-49c7-88fa-69cb16864f9f\" data-root-id=\"866ae1fb-28ad-4096-998c-eafb071b088f\" style=\"display: contents;\"></div>\n",
       "</div>\n",
       "<script type=\"application/javascript\">(function(root) {\n",
       "  var docs_json = {\"d0211663-1407-496c-a42f-9e080498e524\":{\"version\":\"3.4.1\",\"title\":\"Bokeh Application\",\"roots\":[{\"type\":\"object\",\"name\":\"panel.models.browser.BrowserInfo\",\"id\":\"866ae1fb-28ad-4096-998c-eafb071b088f\"},{\"type\":\"object\",\"name\":\"panel.models.comm_manager.CommManager\",\"id\":\"e4e26a03-7d2d-4a39-b74c-1d74579883e7\",\"attributes\":{\"plot_id\":\"866ae1fb-28ad-4096-998c-eafb071b088f\",\"comm_id\":\"2f7decc8683f46bdb64dc37b4ad0a402\",\"client_comm_id\":\"2e7fe83a4a7943fa8c071a4541be7495\"}}],\"defs\":[{\"type\":\"model\",\"name\":\"ReactiveHTML1\"},{\"type\":\"model\",\"name\":\"FlexBox1\",\"properties\":[{\"name\":\"align_content\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"align_items\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"flex_direction\",\"kind\":\"Any\",\"default\":\"row\"},{\"name\":\"flex_wrap\",\"kind\":\"Any\",\"default\":\"wrap\"},{\"name\":\"gap\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"justify_content\",\"kind\":\"Any\",\"default\":\"flex-start\"}]},{\"type\":\"model\",\"name\":\"FloatPanel1\",\"properties\":[{\"name\":\"config\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"contained\",\"kind\":\"Any\",\"default\":true},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"right-top\"},{\"name\":\"offsetx\",\"kind\":\"Any\",\"default\":null},{\"name\":\"offsety\",\"kind\":\"Any\",\"default\":null},{\"name\":\"theme\",\"kind\":\"Any\",\"default\":\"primary\"},{\"name\":\"status\",\"kind\":\"Any\",\"default\":\"normalized\"}]},{\"type\":\"model\",\"name\":\"GridStack1\",\"properties\":[{\"name\":\"mode\",\"kind\":\"Any\",\"default\":\"warn\"},{\"name\":\"ncols\",\"kind\":\"Any\",\"default\":null},{\"name\":\"nrows\",\"kind\":\"Any\",\"default\":null},{\"name\":\"allow_resize\",\"kind\":\"Any\",\"default\":true},{\"name\":\"allow_drag\",\"kind\":\"Any\",\"default\":true},{\"name\":\"state\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"drag1\",\"properties\":[{\"name\":\"slider_width\",\"kind\":\"Any\",\"default\":5},{\"name\":\"slider_color\",\"kind\":\"Any\",\"default\":\"black\"},{\"name\":\"value\",\"kind\":\"Any\",\"default\":50}]},{\"type\":\"model\",\"name\":\"click1\",\"properties\":[{\"name\":\"terminal_output\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"debug_name\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"clears\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"FastWrapper1\",\"properties\":[{\"name\":\"object\",\"kind\":\"Any\",\"default\":null},{\"name\":\"style\",\"kind\":\"Any\",\"default\":null}]},{\"type\":\"model\",\"name\":\"NotificationAreaBase1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"NotificationArea1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"notifications\",\"kind\":\"Any\",\"default\":[]},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0},{\"name\":\"types\",\"kind\":\"Any\",\"default\":[{\"type\":\"map\",\"entries\":[[\"type\",\"warning\"],[\"background\",\"#ffc107\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-exclamation-triangle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]},{\"type\":\"map\",\"entries\":[[\"type\",\"info\"],[\"background\",\"#007bff\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-info-circle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]}]}]},{\"type\":\"model\",\"name\":\"Notification\",\"properties\":[{\"name\":\"background\",\"kind\":\"Any\",\"default\":null},{\"name\":\"duration\",\"kind\":\"Any\",\"default\":3000},{\"name\":\"icon\",\"kind\":\"Any\",\"default\":null},{\"name\":\"message\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"notification_type\",\"kind\":\"Any\",\"default\":null},{\"name\":\"_destroyed\",\"kind\":\"Any\",\"default\":false}]},{\"type\":\"model\",\"name\":\"TemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"BootstrapTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"TemplateEditor1\",\"properties\":[{\"name\":\"layout\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"MaterialTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"copy_to_clipboard1\",\"properties\":[{\"name\":\"fill\",\"kind\":\"Any\",\"default\":\"none\"},{\"name\":\"value\",\"kind\":\"Any\",\"default\":null}]}]}};\n",
       "  var render_items = [{\"docid\":\"d0211663-1407-496c-a42f-9e080498e524\",\"roots\":{\"866ae1fb-28ad-4096-998c-eafb071b088f\":\"cda7d7d4-c6d9-49c7-88fa-69cb16864f9f\"},\"root_ids\":[\"866ae1fb-28ad-4096-998c-eafb071b088f\"]}];\n",
       "  var docs = Object.values(docs_json)\n",
       "  if (!docs) {\n",
       "    return\n",
       "  }\n",
       "  const py_version = docs[0].version.replace('rc', '-rc.').replace('.dev', '-dev.')\n",
       "  async function embed_document(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    await Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "    for (const render_item of render_items) {\n",
       "      for (const root_id of render_item.root_ids) {\n",
       "\tconst id_el = document.getElementById(root_id)\n",
       "\tif (id_el.children.length && id_el.children[0].hasAttribute('data-root-id')) {\n",
       "\t  const root_el = id_el.children[0]\n",
       "\t  root_el.id = root_el.id + '-rendered'\n",
       "\t  for (const child of root_el.children) {\n",
       "            // Ensure JupyterLab does not capture keyboard shortcuts\n",
       "            // see: https://jupyterlab.readthedocs.io/en/4.1.x/extension/notebook.html#keyboard-interaction-model\n",
       "\t    child.setAttribute('data-lm-suppress-shortcuts', 'true')\n",
       "\t  }\n",
       "\t}\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  function get_bokeh(root) {\n",
       "    if (root.Bokeh === undefined) {\n",
       "      return null\n",
       "    } else if (root.Bokeh.version !== py_version) {\n",
       "      if (root.Bokeh.versions === undefined || !root.Bokeh.versions.has(py_version)) {\n",
       "\treturn null\n",
       "      }\n",
       "      return root.Bokeh.versions.get(py_version);\n",
       "    } else if (root.Bokeh.version === py_version) {\n",
       "      return root.Bokeh\n",
       "    }\n",
       "    return null\n",
       "  }\n",
       "  function is_loaded(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    return (Bokeh != null && Bokeh.Panel !== undefined)\n",
       "  }\n",
       "  if (is_loaded(root)) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (is_loaded(root)) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else if (document.readyState == \"complete\") {\n",
       "        attempts++;\n",
       "        if (attempts > 200) {\n",
       "          clearInterval(timer);\n",
       "\t  var Bokeh = get_bokeh(root)\n",
       "\t  if (Bokeh == null || Bokeh.Panel == null) {\n",
       "            console.warn(\"Panel: ERROR: Unable to run Panel code because Bokeh or Panel library is missing\");\n",
       "\t  } else {\n",
       "\t    console.warn(\"Panel: WARNING: Attempting to render but not all required libraries could be resolved.\")\n",
       "\t    embed_document(root)\n",
       "\t  }\n",
       "        }\n",
       "      }\n",
       "    }, 25, root)\n",
       "  }\n",
       "})(window);</script>"
      ]
     },
     "metadata": {
      "application/vnd.holoviews_exec.v0+json": {
       "id": "866ae1fb-28ad-4096-998c-eafb071b088f"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.holoviews_exec.v0+json": "",
      "text/html": [
       "<div id='51aa50b3-d726-4c26-92ad-b362be490f12'>\n",
       "  <div id=\"f2d1a758-0fb2-4e25-86da-98c267cd7518\" data-root-id=\"51aa50b3-d726-4c26-92ad-b362be490f12\" style=\"display: contents;\"></div>\n",
       "</div>\n",
       "<script type=\"application/javascript\">(function(root) {\n",
       "  var docs_json = {\"ef266fb7-45ca-449f-b583-aec6e0b93c1f\":{\"version\":\"3.4.1\",\"title\":\"Bokeh Application\",\"roots\":[{\"type\":\"object\",\"name\":\"panel.models.layout.Card\",\"id\":\"51aa50b3-d726-4c26-92ad-b362be490f12\",\"attributes\":{\"name\":\"Card00144\",\"css_classes\":[\"chat-interface\"],\"styles\":{\"type\":\"map\",\"entries\":[[\"padding\",\"0px\"]]},\"stylesheets\":[\"\\n:host(.pn-loading):before, .pn-loading:before {\\n  background-color: #c3c3c3;\\n  mask-size: auto calc(min(50%, 400px));\\n  -webkit-mask-size: auto calc(min(50%, 400px));\\n}\",{\"type\":\"object\",\"name\":\"ImportedStyleSheet\",\"id\":\"83a076fb-4ab6-47d9-8787-369dccaee28b\",\"attributes\":{\"url\":\"https://cdn.holoviz.org/panel/1.4.5/dist/css/loading.css\"}},{\"type\":\"object\",\"name\":\"ImportedStyleSheet\",\"id\":\"96a5d3c3-6a2e-4e73-9b2e-03c9bc6c0cce\",\"attributes\":{\"url\":\"https://cdn.holoviz.org/panel/1.4.5/dist/css/listpanel.css\"}},{\"type\":\"object\",\"name\":\"ImportedStyleSheet\",\"id\":\"2d657b32-7ca2-43e9-998f-41ef990c6dd6\",\"attributes\":{\"url\":\"https://cdn.holoviz.org/panel/1.4.5/dist/bundled/theme/default.css\"}},{\"type\":\"object\",\"name\":\"ImportedStyleSheet\",\"id\":\"17280549-6798-4e1c-b2cd-5af698a43b2e\",\"attributes\":{\"url\":\"https://cdn.holoviz.org/panel/1.4.5/dist/bundled/theme/native.css\"}},{\"type\":\"object\",\"name\":\"ImportedStyleSheet\",\"id\":\"e71b072c-1b1b-471f-a2ff-308a3ed5b435\",\"attributes\":{\"url\":\"https://cdn.holoviz.org/panel/1.4.5/dist/css/chat_interface.css\"}}],\"margin\":5,\"sizing_mode\":\"stretch_both\",\"align\":\"start\",\"children\":[{\"type\":\"object\",\"name\":\"Row\",\"id\":\"fd4d2865-d2bc-4144-9f74-044cbfee8113\",\"attributes\":{\"name\":\"Row00143\",\"css_classes\":[\"card-header-row\"],\"stylesheets\":[\"\\n:host(.pn-loading):before, .pn-loading:before {\\n  background-color: #c3c3c3;\\n  mask-size: auto calc(min(50%, 400px));\\n  -webkit-mask-size: auto calc(min(50%, 400px));\\n}\",{\"id\":\"83a076fb-4ab6-47d9-8787-369dccaee28b\"},{\"id\":\"96a5d3c3-6a2e-4e73-9b2e-03c9bc6c0cce\"},{\"id\":\"2d657b32-7ca2-43e9-998f-41ef990c6dd6\"},{\"id\":\"17280549-6798-4e1c-b2cd-5af698a43b2e\"}],\"margin\":0,\"sizing_mode\":\"stretch_width\",\"align\":\"start\",\"children\":[{\"type\":\"object\",\"name\":\"panel.models.markup.HTML\",\"id\":\"8baeea4c-3d51-4916-bce1-14bfb4b8fc14\",\"attributes\":{\"css_classes\":[\"chat-feed-title\"],\"stylesheets\":[\"\\n:host(.pn-loading):before, .pn-loading:before {\\n  background-color: #c3c3c3;\\n  mask-size: auto calc(min(50%, 400px));\\n  -webkit-mask-size: auto calc(min(50%, 400px));\\n}\",{\"id\":\"83a076fb-4ab6-47d9-8787-369dccaee28b\"},{\"id\":\"2d657b32-7ca2-43e9-998f-41ef990c6dd6\"},{\"id\":\"17280549-6798-4e1c-b2cd-5af698a43b2e\"}],\"margin\":[5,0],\"align\":\"start\",\"text\":\"&amp;#8203;\",\"disable_math\":true}}]}},{\"type\":\"object\",\"name\":\"panel.models.feed.Feed\",\"id\":\"9588701c-396e-4012-95e1-622275256923\",\"attributes\":{\"name\":\"Feed00141\",\"subscribed_events\":{\"type\":\"set\",\"entries\":[\"scroll_button_click\"]},\"css_classes\":[\"chat-feed-log\",\"scroll-vertical\"],\"stylesheets\":[\"\\n:host(.pn-loading):before, .pn-loading:before {\\n  background-color: #c3c3c3;\\n  mask-size: auto calc(min(50%, 400px));\\n  -webkit-mask-size: auto calc(min(50%, 400px));\\n}\",{\"id\":\"83a076fb-4ab6-47d9-8787-369dccaee28b\"},{\"id\":\"96a5d3c3-6a2e-4e73-9b2e-03c9bc6c0cce\"},{\"id\":\"2d657b32-7ca2-43e9-998f-41ef990c6dd6\"},{\"id\":\"17280549-6798-4e1c-b2cd-5af698a43b2e\"},{\"id\":\"e71b072c-1b1b-471f-a2ff-308a3ed5b435\"}],\"margin\":0,\"sizing_mode\":\"stretch_width\",\"align\":\"start\",\"auto_scroll_limit\":200,\"scroll_button_threshold\":100,\"view_latest\":true}},{\"type\":\"object\",\"name\":\"Spacer\",\"id\":\"669ed3cf-5606-48ec-9637-bbf108757574\",\"attributes\":{\"name\":\"VSpacer00142\",\"stylesheets\":[\"\\n:host(.pn-loading):before, .pn-loading:before {\\n  background-color: #c3c3c3;\\n  mask-size: auto calc(min(50%, 400px));\\n  -webkit-mask-size: auto calc(min(50%, 400px));\\n}\",{\"id\":\"83a076fb-4ab6-47d9-8787-369dccaee28b\"},{\"id\":\"2d657b32-7ca2-43e9-998f-41ef990c6dd6\"},{\"id\":\"17280549-6798-4e1c-b2cd-5af698a43b2e\"}],\"margin\":0,\"sizing_mode\":\"stretch_height\",\"align\":\"start\"}},{\"type\":\"object\",\"name\":\"Row\",\"id\":\"5f528dcf-c6cf-41a7-9615-da45abb9ae5e\",\"attributes\":{\"name\":\"Row00147\",\"css_classes\":[\"chat-interface-input-container\"],\"stylesheets\":[\"\\n:host(.pn-loading):before, .pn-loading:before {\\n  background-color: #c3c3c3;\\n  mask-size: auto calc(min(50%, 400px));\\n  -webkit-mask-size: auto calc(min(50%, 400px));\\n}\",{\"id\":\"83a076fb-4ab6-47d9-8787-369dccaee28b\"},{\"id\":\"96a5d3c3-6a2e-4e73-9b2e-03c9bc6c0cce\"},{\"id\":\"2d657b32-7ca2-43e9-998f-41ef990c6dd6\"},{\"id\":\"17280549-6798-4e1c-b2cd-5af698a43b2e\"},{\"id\":\"e71b072c-1b1b-471f-a2ff-308a3ed5b435\"}],\"margin\":0,\"sizing_mode\":\"stretch_width\",\"align\":\"start\",\"children\":[{\"type\":\"object\",\"name\":\"Row\",\"id\":\"e97537ed-9629-492b-a4a2-b60b00c46f67\",\"attributes\":{\"name\":\"Row00164\",\"css_classes\":[\"chat-interface-input-row\"],\"stylesheets\":[\"\\n:host(.pn-loading):before, .pn-loading:before {\\n  background-color: #c3c3c3;\\n  mask-size: auto calc(min(50%, 400px));\\n  -webkit-mask-size: auto calc(min(50%, 400px));\\n}\",{\"id\":\"83a076fb-4ab6-47d9-8787-369dccaee28b\"},{\"id\":\"96a5d3c3-6a2e-4e73-9b2e-03c9bc6c0cce\"},{\"id\":\"2d657b32-7ca2-43e9-998f-41ef990c6dd6\"},{\"id\":\"17280549-6798-4e1c-b2cd-5af698a43b2e\"},{\"id\":\"e71b072c-1b1b-471f-a2ff-308a3ed5b435\"}],\"margin\":0,\"sizing_mode\":\"stretch_width\",\"align\":\"start\",\"children\":[{\"type\":\"object\",\"name\":\"panel.models.chatarea_input.ChatAreaInput\",\"id\":\"5cf9c73f-9cbc-49f3-ba47-64143e411286\",\"attributes\":{\"subscribed_events\":{\"type\":\"set\",\"entries\":[\"chat_message_event\"]},\"css_classes\":[\"chat-interface-input-widget\"],\"stylesheets\":[\"\\n:host(.pn-loading):before, .pn-loading:before {\\n  background-color: #c3c3c3;\\n  mask-size: auto calc(min(50%, 400px));\\n  -webkit-mask-size: auto calc(min(50%, 400px));\\n}\",{\"id\":\"83a076fb-4ab6-47d9-8787-369dccaee28b\"},{\"id\":\"2d657b32-7ca2-43e9-998f-41ef990c6dd6\"},{\"id\":\"17280549-6798-4e1c-b2cd-5af698a43b2e\"}],\"width\":300,\"margin\":[5,10],\"sizing_mode\":\"stretch_width\",\"align\":\"start\",\"resizable\":\"height\",\"placeholder\":\"Send a message\",\"max_length\":5000,\"rows\":1,\"auto_grow\":true,\"max_rows\":10}},{\"type\":\"object\",\"name\":\"panel.models.widgets.Button\",\"id\":\"91ad4eb0-9fd5-4b55-8e6d-32dd3c9af834\",\"attributes\":{\"subscribed_events\":{\"type\":\"set\",\"entries\":[\"button_click\"]},\"css_classes\":[\"solid\"],\"stylesheets\":[\"\\n:host(.pn-loading):before, .pn-loading:before {\\n  background-color: #c3c3c3;\\n  mask-size: auto calc(min(50%, 400px));\\n  -webkit-mask-size: auto calc(min(50%, 400px));\\n}\",{\"id\":\"83a076fb-4ab6-47d9-8787-369dccaee28b\"},{\"type\":\"object\",\"name\":\"ImportedStyleSheet\",\"id\":\"27a45ec7-8935-4f5c-9972-740e08025dc8\",\"attributes\":{\"url\":\"https://cdn.holoviz.org/panel/1.4.5/dist/css/button.css\"}},{\"id\":\"2d657b32-7ca2-43e9-998f-41ef990c6dd6\"},{\"id\":\"17280549-6798-4e1c-b2cd-5af698a43b2e\"}],\"max_width\":90,\"max_height\":50,\"margin\":[0,5,0,0],\"sizing_mode\":\"stretch_width\",\"align\":\"center\",\"label\":\"Send\",\"icon\":{\"type\":\"object\",\"name\":\"TablerIcon\",\"id\":\"3d4064d2-f1dc-4a19-825f-aa2f0acf6c34\",\"attributes\":{\"icon_name\":\"send\"}}}},{\"type\":\"object\",\"name\":\"panel.models.widgets.Button\",\"id\":\"67000ea3-0c92-46fc-9652-5d5afd8e94de\",\"attributes\":{\"subscribed_events\":{\"type\":\"set\",\"entries\":[\"button_click\"]},\"visible\":false,\"css_classes\":[\"solid\"],\"stylesheets\":[\"\\n:host(.pn-loading):before, .pn-loading:before {\\n  background-color: #c3c3c3;\\n  mask-size: auto calc(min(50%, 400px));\\n  -webkit-mask-size: auto calc(min(50%, 400px));\\n}\",{\"id\":\"83a076fb-4ab6-47d9-8787-369dccaee28b\"},{\"id\":\"27a45ec7-8935-4f5c-9972-740e08025dc8\"},{\"id\":\"2d657b32-7ca2-43e9-998f-41ef990c6dd6\"},{\"id\":\"17280549-6798-4e1c-b2cd-5af698a43b2e\"}],\"max_width\":90,\"max_height\":50,\"margin\":[0,5,0,0],\"sizing_mode\":\"stretch_width\",\"align\":\"center\",\"label\":\"Stop\",\"icon\":{\"type\":\"object\",\"name\":\"TablerIcon\",\"id\":\"650e282d-9a72-41a1-a40c-e803911751f9\",\"attributes\":{\"icon_name\":\"player-stop\"}}}},{\"type\":\"object\",\"name\":\"panel.models.widgets.Button\",\"id\":\"8672ca4b-413b-4bdd-b6c9-aa18ff1d187e\",\"attributes\":{\"subscribed_events\":{\"type\":\"set\",\"entries\":[\"button_click\"]},\"css_classes\":[\"solid\"],\"stylesheets\":[\"\\n:host(.pn-loading):before, .pn-loading:before {\\n  background-color: #c3c3c3;\\n  mask-size: auto calc(min(50%, 400px));\\n  -webkit-mask-size: auto calc(min(50%, 400px));\\n}\",{\"id\":\"83a076fb-4ab6-47d9-8787-369dccaee28b\"},{\"id\":\"27a45ec7-8935-4f5c-9972-740e08025dc8\"},{\"id\":\"2d657b32-7ca2-43e9-998f-41ef990c6dd6\"},{\"id\":\"17280549-6798-4e1c-b2cd-5af698a43b2e\"}],\"max_width\":90,\"max_height\":50,\"margin\":[0,5,0,0],\"sizing_mode\":\"stretch_width\",\"align\":\"center\",\"label\":\"Rerun\",\"icon\":{\"type\":\"object\",\"name\":\"TablerIcon\",\"id\":\"0ecd6bc9-3888-4479-bf45-95887616be5e\",\"attributes\":{\"icon_name\":\"repeat\"}}}},{\"type\":\"object\",\"name\":\"panel.models.widgets.Button\",\"id\":\"97537e96-77d1-440a-ba90-cdada84cc307\",\"attributes\":{\"subscribed_events\":{\"type\":\"set\",\"entries\":[\"button_click\"]},\"css_classes\":[\"solid\"],\"stylesheets\":[\"\\n:host(.pn-loading):before, .pn-loading:before {\\n  background-color: #c3c3c3;\\n  mask-size: auto calc(min(50%, 400px));\\n  -webkit-mask-size: auto calc(min(50%, 400px));\\n}\",{\"id\":\"83a076fb-4ab6-47d9-8787-369dccaee28b\"},{\"id\":\"27a45ec7-8935-4f5c-9972-740e08025dc8\"},{\"id\":\"2d657b32-7ca2-43e9-998f-41ef990c6dd6\"},{\"id\":\"17280549-6798-4e1c-b2cd-5af698a43b2e\"}],\"max_width\":90,\"max_height\":50,\"margin\":[0,5,0,0],\"sizing_mode\":\"stretch_width\",\"align\":\"center\",\"label\":\"Undo\",\"icon\":{\"type\":\"object\",\"name\":\"TablerIcon\",\"id\":\"302288aa-7802-4616-bd7a-aff6934c331f\",\"attributes\":{\"icon_name\":\"arrow-back\"}}}},{\"type\":\"object\",\"name\":\"panel.models.widgets.Button\",\"id\":\"167941c6-4310-4da6-b85d-ce867ac69256\",\"attributes\":{\"subscribed_events\":{\"type\":\"set\",\"entries\":[\"button_click\"]},\"css_classes\":[\"solid\"],\"stylesheets\":[\"\\n:host(.pn-loading):before, .pn-loading:before {\\n  background-color: #c3c3c3;\\n  mask-size: auto calc(min(50%, 400px));\\n  -webkit-mask-size: auto calc(min(50%, 400px));\\n}\",{\"id\":\"83a076fb-4ab6-47d9-8787-369dccaee28b\"},{\"id\":\"27a45ec7-8935-4f5c-9972-740e08025dc8\"},{\"id\":\"2d657b32-7ca2-43e9-998f-41ef990c6dd6\"},{\"id\":\"17280549-6798-4e1c-b2cd-5af698a43b2e\"}],\"max_width\":90,\"max_height\":50,\"margin\":[0,5,0,0],\"sizing_mode\":\"stretch_width\",\"align\":\"center\",\"label\":\"Clear\",\"icon\":{\"type\":\"object\",\"name\":\"TablerIcon\",\"id\":\"61cf433f-2b18-46da-8805-78909f1d8f74\",\"attributes\":{\"icon_name\":\"trash\"}}}}]}}]}}],\"active_header_background\":\"\",\"button_css_classes\":[\"card-button\"],\"collapsed\":false,\"collapsible\":false,\"header_background\":\"\",\"header_color\":\"\",\"header_css_classes\":[\"chat-feed-header\"],\"hide_header\":true}},{\"type\":\"object\",\"name\":\"panel.models.comm_manager.CommManager\",\"id\":\"4df6c2e1-aedd-425e-bdfe-94c1b3104aa0\",\"attributes\":{\"plot_id\":\"51aa50b3-d726-4c26-92ad-b362be490f12\",\"comm_id\":\"8a8b309fe7ba4a6898e6acdfec021e8f\",\"client_comm_id\":\"f215e26e358e41dd929ecf5693548d17\"}}],\"defs\":[{\"type\":\"model\",\"name\":\"ReactiveHTML1\"},{\"type\":\"model\",\"name\":\"FlexBox1\",\"properties\":[{\"name\":\"align_content\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"align_items\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"flex_direction\",\"kind\":\"Any\",\"default\":\"row\"},{\"name\":\"flex_wrap\",\"kind\":\"Any\",\"default\":\"wrap\"},{\"name\":\"gap\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"justify_content\",\"kind\":\"Any\",\"default\":\"flex-start\"}]},{\"type\":\"model\",\"name\":\"FloatPanel1\",\"properties\":[{\"name\":\"config\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"contained\",\"kind\":\"Any\",\"default\":true},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"right-top\"},{\"name\":\"offsetx\",\"kind\":\"Any\",\"default\":null},{\"name\":\"offsety\",\"kind\":\"Any\",\"default\":null},{\"name\":\"theme\",\"kind\":\"Any\",\"default\":\"primary\"},{\"name\":\"status\",\"kind\":\"Any\",\"default\":\"normalized\"}]},{\"type\":\"model\",\"name\":\"GridStack1\",\"properties\":[{\"name\":\"mode\",\"kind\":\"Any\",\"default\":\"warn\"},{\"name\":\"ncols\",\"kind\":\"Any\",\"default\":null},{\"name\":\"nrows\",\"kind\":\"Any\",\"default\":null},{\"name\":\"allow_resize\",\"kind\":\"Any\",\"default\":true},{\"name\":\"allow_drag\",\"kind\":\"Any\",\"default\":true},{\"name\":\"state\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"drag1\",\"properties\":[{\"name\":\"slider_width\",\"kind\":\"Any\",\"default\":5},{\"name\":\"slider_color\",\"kind\":\"Any\",\"default\":\"black\"},{\"name\":\"value\",\"kind\":\"Any\",\"default\":50}]},{\"type\":\"model\",\"name\":\"click1\",\"properties\":[{\"name\":\"terminal_output\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"debug_name\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"clears\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"FastWrapper1\",\"properties\":[{\"name\":\"object\",\"kind\":\"Any\",\"default\":null},{\"name\":\"style\",\"kind\":\"Any\",\"default\":null}]},{\"type\":\"model\",\"name\":\"NotificationAreaBase1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"NotificationArea1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"notifications\",\"kind\":\"Any\",\"default\":[]},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0},{\"name\":\"types\",\"kind\":\"Any\",\"default\":[{\"type\":\"map\",\"entries\":[[\"type\",\"warning\"],[\"background\",\"#ffc107\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-exclamation-triangle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]},{\"type\":\"map\",\"entries\":[[\"type\",\"info\"],[\"background\",\"#007bff\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-info-circle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]}]}]},{\"type\":\"model\",\"name\":\"Notification\",\"properties\":[{\"name\":\"background\",\"kind\":\"Any\",\"default\":null},{\"name\":\"duration\",\"kind\":\"Any\",\"default\":3000},{\"name\":\"icon\",\"kind\":\"Any\",\"default\":null},{\"name\":\"message\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"notification_type\",\"kind\":\"Any\",\"default\":null},{\"name\":\"_destroyed\",\"kind\":\"Any\",\"default\":false}]},{\"type\":\"model\",\"name\":\"TemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"BootstrapTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"TemplateEditor1\",\"properties\":[{\"name\":\"layout\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"MaterialTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"copy_to_clipboard1\",\"properties\":[{\"name\":\"fill\",\"kind\":\"Any\",\"default\":\"none\"},{\"name\":\"value\",\"kind\":\"Any\",\"default\":null}]}]}};\n",
       "  var render_items = [{\"docid\":\"ef266fb7-45ca-449f-b583-aec6e0b93c1f\",\"roots\":{\"51aa50b3-d726-4c26-92ad-b362be490f12\":\"f2d1a758-0fb2-4e25-86da-98c267cd7518\"},\"root_ids\":[\"51aa50b3-d726-4c26-92ad-b362be490f12\"]}];\n",
       "  var docs = Object.values(docs_json)\n",
       "  if (!docs) {\n",
       "    return\n",
       "  }\n",
       "  const py_version = docs[0].version.replace('rc', '-rc.').replace('.dev', '-dev.')\n",
       "  async function embed_document(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    await Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "    for (const render_item of render_items) {\n",
       "      for (const root_id of render_item.root_ids) {\n",
       "\tconst id_el = document.getElementById(root_id)\n",
       "\tif (id_el.children.length && id_el.children[0].hasAttribute('data-root-id')) {\n",
       "\t  const root_el = id_el.children[0]\n",
       "\t  root_el.id = root_el.id + '-rendered'\n",
       "\t  for (const child of root_el.children) {\n",
       "            // Ensure JupyterLab does not capture keyboard shortcuts\n",
       "            // see: https://jupyterlab.readthedocs.io/en/4.1.x/extension/notebook.html#keyboard-interaction-model\n",
       "\t    child.setAttribute('data-lm-suppress-shortcuts', 'true')\n",
       "\t  }\n",
       "\t}\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  function get_bokeh(root) {\n",
       "    if (root.Bokeh === undefined) {\n",
       "      return null\n",
       "    } else if (root.Bokeh.version !== py_version) {\n",
       "      if (root.Bokeh.versions === undefined || !root.Bokeh.versions.has(py_version)) {\n",
       "\treturn null\n",
       "      }\n",
       "      return root.Bokeh.versions.get(py_version);\n",
       "    } else if (root.Bokeh.version === py_version) {\n",
       "      return root.Bokeh\n",
       "    }\n",
       "    return null\n",
       "  }\n",
       "  function is_loaded(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    return (Bokeh != null && Bokeh.Panel !== undefined)\n",
       "  }\n",
       "  if (is_loaded(root)) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (is_loaded(root)) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else if (document.readyState == \"complete\") {\n",
       "        attempts++;\n",
       "        if (attempts > 200) {\n",
       "          clearInterval(timer);\n",
       "\t  var Bokeh = get_bokeh(root)\n",
       "\t  if (Bokeh == null || Bokeh.Panel == null) {\n",
       "            console.warn(\"Panel: ERROR: Unable to run Panel code because Bokeh or Panel library is missing\");\n",
       "\t  } else {\n",
       "\t    console.warn(\"Panel: WARNING: Attempting to render but not all required libraries could be resolved.\")\n",
       "\t    embed_document(root)\n",
       "\t  }\n",
       "        }\n",
       "      }\n",
       "    }, 25, root)\n",
       "  }\n",
       "})(window);</script>"
      ],
      "text/plain": [
       "ChatInterface(_button_data={'send': _ChatButtonData(i...}, _buttons={'send': Button(align='cen...}, _input_container=Row, _input_layout=Row, _placeholder=ChatMessage, _widgets={'ChatAreaInput': ChatArea...}, callback=<function callback a..., callback_user='Shrek director', show_button_name=True, sizing_mode='stretch_width', widgets=[ChatAreaInput(css_classes...])"
      ]
     },
     "execution_count": 26,
     "metadata": {
      "application/vnd.holoviews_exec.v0+json": {
       "id": "51aa50b3-d726-4c26-92ad-b362be490f12"
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import panel as pn\n",
    "\n",
    "pn.extension()\n",
    "\n",
    "\n",
    "async def callback(contents: str, user: str, instance: pn.chat.ChatInterface):\n",
    "    message = \"\"\n",
    "    for response in rag_chain.stream(contents, config=config):\n",
    "        message += response.content\n",
    "        yield message\n",
    "\n",
    "\n",
    "config = {\"configurable\": {\"session_id\": \"rag_session_2\"}}\n",
    "chat_interface = pn.chat.ChatInterface(callback=callback, callback_user=\"Shrek director\")\n",
    "chat_interface.servable()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional task - use HuggingFace model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to /Users/wiktorsmura/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parent run acd4971b-4e15-4e32-bdfd-686be8751834 not found for run 22620778-c886-4e3b-a3f4-d245a2dad4a7. Treating as a root run.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In \"Shrek Goes To Town,\" Shrek is partnered with Donkey when rescuing Fiona. Donkey is Shrek's faithful companion and loyal friend.\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import ChatHuggingFace, HuggingFacePipeline\n",
    "from huggingface_hub import login\n",
    "\n",
    "HF_TOKEN = os.environ.get(\"HUGGINGFACEHUB_API_TOKEN\")\n",
    "\n",
    "login(token=HF_TOKEN)\n",
    "\n",
    "llm = HuggingFacePipeline.from_model_id(\n",
    "    model_id=\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\",\n",
    "    task=\"text-generation\",\n",
    "    pipeline_kwargs=dict(\n",
    "        max_new_tokens=512,\n",
    "        return_full_text=False,\n",
    "        do_sample=True,\n",
    "        repetition_penalty=1.03,\n",
    "        temperature=0.1\n",
    "    ),\n",
    ")\n",
    "\n",
    "hg_model = ChatHuggingFace(llm=llm)\n",
    "chain = prompt | hg_model\n",
    "hg_chain_with_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"chat_history\",\n",
    ")\n",
    "rag_chain = {\n",
    "    \"context\": retriever | format_docs,\n",
    "    \"input\": RunnablePassthrough(),\n",
    "} | hg_chain_with_history\n",
    "\n",
    "response = rag_chain.invoke(\"Who was Shrek's partner when rescuing Fiona?\", config=config)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
